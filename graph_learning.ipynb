{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import edt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from skimage.metrics import adapted_rand_error\n",
    "\n",
    "import torch\n",
    "from torch import from_numpy as from_numpy\n",
    "from torchsummary import summary\n",
    "\n",
    "import dgl\n",
    "\n",
    "from func.run_pipeline_super_vox import segment_super_vox_3_channel, semantic_segment_crop_and_cat_3_channel_output, img_3d_erosion_or_expansion, \\\n",
    "generate_super_vox_by_watershed, get_outlayer_of_a_3d_shape, get_crop_by_pixel_val, Cluster_Super_Vox, assign_boudary_voxels_to_cells_with_watershed, \\\n",
    "delete_too_small_cluster, reassign\n",
    "from func.run_pipeline import segment, assign_boudary_voxels_to_cells, dbscan_of_seg, semantic_segment_crop_and_cat\n",
    "from func.cal_accuracy import IOU_and_Dice_Accuracy, VOI\n",
    "from func.network import VoxResNet, CellSegNet_basic_lite\n",
    "from func.unet_3d_basic import UNet3D_basic\n",
    "from func.ultis import save_obj, load_obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HMS_data_dict = load_obj(\"dataset_info/HMS_dataset_info\")\n",
    "HMS_data_dict_test = HMS_data_dict[\"test\"]\n",
    "print(\"Test cases: \"+str(HMS_data_dict_test.keys()))\n",
    "case = \"135\"\n",
    "print(\"for test case \"+str(case)+\" : \"+str(HMS_data_dict_test[case]))\n",
    "\n",
    "# you may load the image using another path\n",
    "raw_img=np.load(HMS_data_dict_test[case][\"raw\"]).astype(float)\n",
    "hand_seg=np.load(HMS_data_dict_test[case][\"ins\"]).astype(float)\n",
    "\n",
    "# np.save('seg_foreground_super_voxel_by_ws_graph.npy', seg_foreground_super_voxel_by_ws)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "seg_foreground_super_voxel_by_ws = np.load('seg_foreground_super_voxel_by_ws_graph.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1951"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(seg_foreground_super_voxel_by_ws))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 9125466,\n 1: 69,\n 2: 35,\n 3: 3,\n 4: 852,\n 5: 53,\n 6: 6,\n 7: 89,\n 8: 36,\n 9: 222,\n 10: 394,\n 11: 7,\n 12: 34,\n 13: 114,\n 14: 9,\n 15: 132,\n 16: 52,\n 17: 108,\n 18: 21,\n 19: 110,\n 20: 262,\n 21: 325,\n 22: 14,\n 23: 181,\n 24: 60,\n 25: 6,\n 26: 161,\n 27: 104,\n 28: 5,\n 29: 15,\n 30: 9,\n 31: 58,\n 32: 5,\n 33: 156,\n 34: 1,\n 35: 9,\n 36: 8,\n 37: 307,\n 38: 2126,\n 39: 338,\n 40: 3,\n 41: 240,\n 42: 275,\n 43: 66,\n 44: 31,\n 45: 260,\n 46: 277,\n 47: 576,\n 48: 306,\n 49: 273,\n 50: 147,\n 51: 105,\n 52: 73,\n 53: 62,\n 54: 16,\n 55: 289,\n 56: 85,\n 57: 860,\n 58: 495,\n 59: 127,\n 60: 71,\n 61: 831,\n 62: 218,\n 63: 9,\n 64: 6,\n 65: 4,\n 66: 15,\n 67: 191,\n 68: 41,\n 69: 87,\n 70: 8,\n 71: 7,\n 72: 515,\n 73: 543,\n 74: 474,\n 75: 3,\n 76: 172,\n 77: 44,\n 78: 410,\n 79: 53,\n 80: 214,\n 81: 603,\n 82: 36,\n 83: 4,\n 84: 5,\n 85: 8,\n 86: 28,\n 87: 14,\n 88: 169,\n 89: 54,\n 90: 865,\n 91: 11,\n 92: 12,\n 93: 155,\n 94: 2,\n 95: 29,\n 96: 22,\n 97: 81,\n 98: 4,\n 99: 302,\n 100: 3,\n 101: 4,\n 102: 433,\n 103: 195,\n 104: 6,\n 105: 617,\n 106: 162,\n 107: 22,\n 108: 26,\n 109: 1,\n 110: 163,\n 111: 231,\n 112: 1045,\n 113: 1407,\n 114: 1,\n 115: 30,\n 116: 2,\n 117: 186,\n 118: 95,\n 119: 20,\n 120: 95,\n 121: 239,\n 122: 6,\n 123: 513,\n 124: 9,\n 125: 12,\n 126: 290,\n 127: 423,\n 128: 78,\n 129: 26,\n 130: 1060,\n 131: 4,\n 132: 6,\n 133: 136,\n 134: 4,\n 135: 13,\n 136: 86,\n 137: 177,\n 138: 3,\n 139: 135,\n 140: 840,\n 141: 477,\n 142: 858,\n 143: 342,\n 144: 388,\n 145: 274,\n 146: 73,\n 147: 1302,\n 148: 1512,\n 149: 351,\n 150: 1414,\n 151: 197,\n 152: 27,\n 153: 120,\n 154: 355,\n 155: 3,\n 156: 9,\n 157: 187,\n 158: 143,\n 159: 360,\n 160: 515,\n 161: 13,\n 162: 16,\n 163: 9,\n 164: 363,\n 165: 401,\n 166: 371,\n 167: 2310,\n 168: 342,\n 169: 105,\n 170: 7,\n 171: 173,\n 172: 163,\n 173: 155,\n 174: 136,\n 175: 198,\n 176: 2,\n 177: 145,\n 178: 1137,\n 179: 1552,\n 180: 77,\n 181: 89,\n 182: 1738,\n 183: 65,\n 184: 248,\n 185: 44,\n 186: 58,\n 187: 49,\n 188: 126,\n 189: 708,\n 190: 3,\n 191: 40,\n 192: 55,\n 193: 14,\n 194: 6,\n 195: 95,\n 196: 25,\n 197: 29,\n 198: 28,\n 199: 6,\n 200: 43,\n 201: 8,\n 202: 581,\n 203: 308,\n 204: 63,\n 205: 51,\n 206: 1137,\n 207: 332,\n 208: 47,\n 209: 6,\n 210: 228,\n 211: 1523,\n 212: 5,\n 213: 452,\n 214: 960,\n 215: 442,\n 216: 56,\n 217: 117,\n 218: 741,\n 219: 75,\n 220: 57,\n 221: 15,\n 222: 5,\n 223: 204,\n 224: 8,\n 225: 55,\n 226: 390,\n 227: 157,\n 228: 190,\n 229: 50,\n 230: 14,\n 231: 1622,\n 232: 176,\n 233: 163,\n 234: 258,\n 235: 50,\n 236: 699,\n 237: 930,\n 238: 175,\n 239: 108,\n 240: 564,\n 241: 157,\n 242: 359,\n 243: 48,\n 244: 196,\n 245: 16,\n 246: 374,\n 247: 632,\n 248: 625,\n 249: 144,\n 250: 77,\n 251: 272,\n 252: 1,\n 253: 3,\n 254: 15,\n 255: 296,\n 256: 39,\n 257: 35,\n 258: 4,\n 259: 336,\n 260: 427,\n 261: 5,\n 262: 1015,\n 263: 833,\n 264: 203,\n 265: 10,\n 266: 13,\n 267: 58,\n 268: 17,\n 269: 257,\n 270: 15,\n 271: 197,\n 272: 13,\n 273: 243,\n 274: 6,\n 275: 305,\n 276: 7,\n 277: 138,\n 278: 150,\n 279: 301,\n 280: 129,\n 281: 54,\n 282: 54,\n 283: 67,\n 284: 75,\n 285: 99,\n 286: 481,\n 287: 17,\n 288: 247,\n 289: 180,\n 290: 331,\n 291: 89,\n 292: 858,\n 293: 42,\n 294: 85,\n 295: 136,\n 296: 338,\n 297: 111,\n 298: 287,\n 299: 244,\n 300: 134,\n 301: 223,\n 302: 165,\n 303: 90,\n 304: 101,\n 305: 316,\n 306: 6,\n 307: 117,\n 308: 149,\n 309: 92,\n 310: 2,\n 311: 53,\n 312: 8,\n 313: 791,\n 314: 118,\n 315: 2,\n 316: 55,\n 317: 75,\n 318: 1,\n 319: 154,\n 320: 160,\n 321: 342,\n 322: 31,\n 323: 15,\n 324: 109,\n 325: 774,\n 326: 1878,\n 327: 1425,\n 328: 9,\n 329: 8,\n 330: 1,\n 331: 289,\n 332: 21,\n 333: 75,\n 334: 115,\n 335: 98,\n 336: 19,\n 337: 71,\n 338: 128,\n 339: 119,\n 340: 339,\n 341: 26,\n 342: 42,\n 343: 21,\n 344: 590,\n 345: 221,\n 346: 2746,\n 347: 17,\n 348: 140,\n 349: 597,\n 350: 72,\n 351: 176,\n 352: 1913,\n 353: 305,\n 354: 229,\n 355: 175,\n 356: 41,\n 357: 249,\n 358: 6,\n 359: 227,\n 360: 527,\n 361: 6,\n 362: 18,\n 363: 361,\n 364: 1074,\n 365: 402,\n 366: 511,\n 367: 233,\n 368: 148,\n 369: 717,\n 370: 98,\n 371: 65,\n 372: 260,\n 373: 114,\n 374: 44,\n 375: 98,\n 376: 27,\n 377: 91,\n 378: 258,\n 379: 16,\n 380: 4,\n 381: 347,\n 382: 280,\n 383: 329,\n 384: 12,\n 385: 847,\n 386: 143,\n 387: 235,\n 388: 639,\n 389: 218,\n 390: 14,\n 391: 243,\n 392: 785,\n 393: 13,\n 394: 99,\n 395: 197,\n 396: 397,\n 397: 4,\n 398: 6,\n 399: 8,\n 400: 38,\n 401: 2359,\n 402: 83,\n 403: 64,\n 404: 115,\n 405: 70,\n 406: 259,\n 407: 724,\n 408: 23,\n 409: 6,\n 410: 437,\n 411: 171,\n 412: 107,\n 413: 754,\n 414: 26,\n 415: 176,\n 416: 769,\n 417: 7,\n 418: 505,\n 419: 76,\n 420: 10,\n 421: 399,\n 422: 152,\n 423: 500,\n 424: 249,\n 425: 34,\n 426: 245,\n 427: 14,\n 428: 138,\n 429: 238,\n 430: 175,\n 431: 549,\n 432: 264,\n 433: 64,\n 434: 44,\n 435: 77,\n 436: 628,\n 437: 71,\n 438: 36,\n 439: 1924,\n 440: 279,\n 441: 115,\n 442: 75,\n 443: 166,\n 444: 95,\n 445: 405,\n 446: 273,\n 447: 138,\n 448: 161,\n 449: 55,\n 450: 407,\n 451: 558,\n 452: 2,\n 453: 5,\n 454: 19,\n 455: 6,\n 456: 884,\n 457: 87,\n 458: 234,\n 459: 45,\n 460: 12,\n 461: 2,\n 462: 4,\n 463: 343,\n 464: 75,\n 465: 76,\n 466: 10,\n 467: 329,\n 468: 101,\n 469: 264,\n 470: 37,\n 471: 166,\n 472: 131,\n 473: 146,\n 474: 130,\n 475: 7,\n 476: 127,\n 477: 58,\n 478: 44,\n 479: 107,\n 480: 1,\n 481: 120,\n 482: 8,\n 483: 257,\n 484: 211,\n 485: 264,\n 486: 201,\n 487: 31,\n 488: 745,\n 489: 12,\n 490: 28,\n 491: 2,\n 492: 56,\n 493: 141,\n 494: 44,\n 495: 217,\n 496: 113,\n 497: 118,\n 498: 54,\n 499: 181,\n 500: 28,\n 501: 1140,\n 502: 35,\n 503: 729,\n 504: 33,\n 505: 52,\n 506: 129,\n 507: 2850,\n 508: 44,\n 509: 112,\n 510: 151,\n 511: 152,\n 512: 125,\n 513: 1671,\n 514: 1652,\n 515: 40,\n 516: 171,\n 517: 362,\n 518: 10,\n 519: 75,\n 520: 74,\n 521: 100,\n 522: 31,\n 523: 34,\n 524: 73,\n 525: 4,\n 526: 1734,\n 527: 227,\n 528: 91,\n 529: 85,\n 530: 250,\n 531: 52,\n 532: 106,\n 533: 80,\n 534: 339,\n 535: 5,\n 536: 83,\n 537: 159,\n 538: 22,\n 539: 1324,\n 540: 69,\n 541: 419,\n 542: 1,\n 543: 207,\n 544: 7,\n 545: 198,\n 546: 21,\n 547: 62,\n 548: 258,\n 549: 13,\n 550: 17,\n 551: 39,\n 552: 459,\n 553: 322,\n 554: 39,\n 555: 239,\n 556: 159,\n 557: 91,\n 558: 40,\n 559: 13,\n 560: 6,\n 561: 54,\n 562: 1353,\n 563: 118,\n 564: 105,\n 565: 121,\n 566: 768,\n 567: 356,\n 568: 168,\n 569: 413,\n 570: 446,\n 571: 44,\n 572: 50,\n 573: 70,\n 574: 125,\n 575: 8,\n 576: 63,\n 577: 6,\n 578: 208,\n 579: 305,\n 580: 27,\n 581: 45,\n 582: 65,\n 583: 141,\n 584: 69,\n 585: 55,\n 586: 91,\n 587: 314,\n 588: 1153,\n 589: 3,\n 590: 204,\n 591: 273,\n 592: 89,\n 593: 414,\n 594: 58,\n 595: 113,\n 596: 123,\n 597: 71,\n 598: 169,\n 599: 163,\n 600: 425,\n 601: 3,\n 602: 5,\n 603: 5,\n 604: 245,\n 605: 58,\n 606: 404,\n 607: 50,\n 608: 49,\n 609: 15,\n 610: 28,\n 611: 43,\n 612: 16,\n 613: 36,\n 614: 50,\n 615: 236,\n 616: 156,\n 617: 14,\n 618: 9,\n 619: 52,\n 620: 46,\n 621: 97,\n 622: 52,\n 623: 110,\n 624: 3131,\n 625: 117,\n 626: 4,\n 627: 698,\n 628: 312,\n 629: 1,\n 630: 14,\n 631: 67,\n 632: 69,\n 633: 407,\n 634: 43,\n 635: 398,\n 636: 23,\n 637: 23,\n 638: 505,\n 639: 139,\n 640: 21,\n 641: 46,\n 642: 42,\n 643: 12,\n 644: 1546,\n 645: 78,\n 646: 176,\n 647: 189,\n 648: 29,\n 649: 22,\n 650: 98,\n 651: 26,\n 652: 744,\n 653: 280,\n 654: 1850,\n 655: 1326,\n 656: 7,\n 657: 1737,\n 658: 623,\n 659: 221,\n 660: 8,\n 661: 7,\n 662: 9,\n 663: 1,\n 664: 10,\n 665: 9,\n 666: 5,\n 667: 142,\n 668: 243,\n 669: 17,\n 670: 341,\n 671: 304,\n 672: 318,\n 673: 8,\n 674: 4,\n 675: 5,\n 676: 14,\n 677: 11,\n 678: 1092,\n 679: 48,\n 680: 33,\n 681: 351,\n 682: 10,\n 683: 135,\n 684: 2121,\n 685: 8,\n 686: 14,\n 687: 6,\n 688: 1478,\n 689: 4,\n 690: 289,\n 691: 5,\n 692: 251,\n 693: 492,\n 694: 282,\n 695: 403,\n 696: 217,\n 697: 733,\n 698: 150,\n 699: 27,\n 700: 37,\n 701: 4,\n 702: 746,\n 703: 37,\n 704: 39,\n 705: 464,\n 706: 38,\n 707: 45,\n 708: 10,\n 709: 484,\n 710: 154,\n 711: 490,\n 712: 1122,\n 713: 657,\n 714: 3,\n 715: 1434,\n 716: 89,\n 717: 336,\n 718: 41,\n 719: 703,\n 720: 5,\n 721: 574,\n 722: 74,\n 723: 141,\n 724: 474,\n 725: 1039,\n 726: 6,\n 727: 179,\n 728: 86,\n 729: 566,\n 730: 5,\n 731: 517,\n 732: 204,\n 733: 82,\n 734: 3,\n 735: 7,\n 736: 18,\n 737: 91,\n 738: 1605,\n 739: 34,\n 740: 68,\n 741: 149,\n 742: 79,\n 743: 458,\n 744: 1254,\n 745: 2,\n 746: 562,\n 747: 10,\n 748: 53,\n 749: 4,\n 750: 137,\n 751: 67,\n 752: 1928,\n 753: 4,\n 754: 20,\n 755: 25,\n 756: 135,\n 757: 115,\n 758: 154,\n 759: 17,\n 760: 8,\n 761: 2132,\n 762: 20,\n 763: 8,\n 764: 2,\n 765: 3,\n 766: 56,\n 767: 194,\n 768: 33,\n 769: 21,\n 770: 10,\n 771: 3,\n 772: 77,\n 773: 117,\n 774: 5,\n 775: 110,\n 776: 219,\n 777: 149,\n 778: 131,\n 779: 162,\n 780: 1577,\n 781: 161,\n 782: 264,\n 783: 7,\n 784: 57,\n 785: 677,\n 786: 73,\n 787: 431,\n 788: 116,\n 789: 203,\n 790: 238,\n 791: 243,\n 792: 246,\n 793: 121,\n 794: 161,\n 795: 33,\n 796: 29,\n 797: 398,\n 798: 5,\n 799: 140,\n 800: 4,\n 801: 764,\n 802: 104,\n 803: 82,\n 804: 119,\n 805: 754,\n 806: 932,\n 807: 45,\n 808: 46,\n 809: 61,\n 810: 77,\n 811: 228,\n 812: 3,\n 813: 601,\n 814: 8,\n 815: 5,\n 816: 102,\n 817: 80,\n 818: 38,\n 819: 9,\n 820: 41,\n 821: 89,\n 822: 2,\n 823: 4,\n 824: 12,\n 825: 9,\n 826: 1192,\n 827: 587,\n 828: 12,\n 829: 8,\n 830: 99,\n 831: 79,\n 832: 14,\n 833: 71,\n 834: 6,\n 835: 13,\n 836: 227,\n 837: 45,\n 838: 143,\n 839: 108,\n 840: 79,\n 841: 134,\n 842: 79,\n 843: 9,\n 844: 1,\n 845: 18,\n 846: 53,\n 847: 104,\n 848: 168,\n 849: 29,\n 850: 96,\n 851: 13,\n 852: 11,\n 853: 2267,\n 854: 816,\n 855: 89,\n 856: 1930,\n 857: 179,\n 858: 10,\n 859: 18,\n 860: 17,\n 861: 26,\n 862: 8,\n 863: 151,\n 864: 410,\n 865: 171,\n 866: 50,\n 867: 103,\n 868: 84,\n 869: 1,\n 870: 19,\n 871: 24,\n 872: 952,\n 873: 252,\n 874: 1243,\n 875: 962,\n 876: 30,\n 877: 4,\n 878: 31,\n 879: 483,\n 880: 499,\n 881: 102,\n 882: 54,\n 883: 121,\n 884: 11,\n 885: 3,\n 886: 1,\n 887: 7,\n 888: 6,\n 889: 4,\n 890: 10,\n 891: 161,\n 892: 20,\n 893: 139,\n 894: 12,\n 895: 264,\n 896: 40,\n 897: 6,\n 898: 9,\n 899: 42,\n 900: 5,\n 901: 61,\n 902: 161,\n 903: 94,\n 904: 4,\n 905: 7,\n 906: 443,\n 907: 2,\n 908: 12,\n 909: 229,\n 910: 2,\n 911: 179,\n 912: 2,\n 913: 3,\n 914: 58,\n 915: 10,\n 916: 6,\n 917: 33,\n 918: 36,\n 919: 589,\n 920: 387,\n 921: 7,\n 922: 343,\n 923: 404,\n 924: 400,\n 925: 122,\n 926: 19,\n 927: 103,\n 928: 92,\n 929: 38,\n 930: 144,\n 931: 6,\n 932: 15,\n 933: 936,\n 934: 912,\n 935: 4,\n 936: 44,\n 937: 44,\n 938: 6,\n 939: 37,\n 940: 22,\n 941: 40,\n 942: 1485,\n 943: 5,\n 944: 108,\n 945: 145,\n 946: 188,\n 947: 1218,\n 948: 5,\n 949: 7,\n 950: 16,\n 951: 26,\n 952: 30,\n 953: 2,\n 954: 130,\n 955: 6,\n 956: 3,\n 957: 90,\n 958: 12,\n 959: 130,\n 960: 26,\n 961: 59,\n 962: 42,\n 963: 45,\n 964: 66,\n 965: 38,\n 966: 63,\n 967: 201,\n 968: 57,\n 969: 51,\n 970: 6,\n 971: 1,\n 972: 3,\n 973: 6,\n 974: 1045,\n 975: 720,\n 976: 1091,\n 977: 99,\n 978: 6,\n 979: 71,\n 980: 47,\n 981: 43,\n 982: 18,\n 983: 829,\n 984: 216,\n 985: 107,\n 986: 483,\n 987: 569,\n 988: 81,\n 989: 37,\n 990: 62,\n 991: 40,\n 992: 74,\n 993: 41,\n 994: 89,\n 995: 38,\n 996: 23,\n 997: 167,\n 998: 369,\n 999: 173,\n ...}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the size of each super voxel\n",
    "\n",
    "unique, counts = np.unique(seg_foreground_super_voxel_by_ws, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Super_Vox_To_Graph_depr():\n",
    "    def __init__(self, boundary_extend=2):\n",
    "        super(Super_Vox_To_Graph, self).__init__\n",
    "        self.boundary_extend = boundary_extend\n",
    "\n",
    "        self.UN_PROCESSED = 0\n",
    "        self.LONELY_POINT = -1\n",
    "        self.A_LARGE_NUM = 100000000\n",
    "\n",
    "    def fit(self, input_3d_img, restrict_area_3d=None):\n",
    "        self.input_3d_img = input_3d_img\n",
    "\n",
    "        if restrict_area_3d is None:\n",
    "            self.restrict_area_3d = np.array(input_3d_img==0, dtype=np.int8)\n",
    "        else:\n",
    "            self.restrict_area_3d = restrict_area_3d\n",
    "\n",
    "        unique_vals, unique_val_counts = np.unique(self.input_3d_img, return_counts=True)\n",
    "        unique_val_counts = unique_val_counts[unique_vals>0]\n",
    "        unique_vals = unique_vals[unique_vals>0]\n",
    "        sort_locs = np.argsort(unique_val_counts)[::-1]\n",
    "        self.unique_vals = unique_vals[sort_locs]\n",
    "\n",
    "        self.val_labels = dict()\n",
    "        for unique_val in self.unique_vals:\n",
    "            self.val_labels[unique_val] = self.UN_PROCESSED\n",
    "\n",
    "        self.val_outlayer_area = dict()\n",
    "        for idx, unique_val in enumerate(self.unique_vals):\n",
    "            # print(\"get val_outlayer area of all vals: \"+str(idx/len(self.unique_vals)))\n",
    "            self.val_outlayer_area[unique_val] = self.A_LARGE_NUM\n",
    "\n",
    "        \"\"\"\n",
    "        neighborhoods_dict:\n",
    "        {\n",
    "            voxel: {\n",
    "                        neighbor_1: touching area,\n",
    "                        neighbor_2: touching area\n",
    "                    }\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        neighborhoods_dict = {}\n",
    "        for idx, current_val in enumerate(self.unique_vals):\n",
    "            # print('processing: '+str(idx/len(self.unique_vals))+' pixel val: '+str(current_val))\n",
    "            if self.val_labels[current_val]!=self.UN_PROCESSED:\n",
    "                continue\n",
    "            valid_neighbor_vals = self.regionQuery(current_val)\n",
    "            neighborhoods_dict[current_val] = valid_neighbor_vals\n",
    "            # if len(valid_neighbor_vals)>0:\n",
    "            #     # print('Assign label '+str(current_val)+' to current val\\'s neighbors: '+str(valid_neighbor_vals))\n",
    "            #    self.val_labels[current_val] = current_val\n",
    "            #    self.growCluster(valid_neighbor_vals, current_val)\n",
    "            # else:\n",
    "            #    self.val_labels[current_val] = self.LONELY_POINT\n",
    "\n",
    "        # self.output_3d_img = self.input_3d_img\n",
    "        return neighborhoods_dict\n",
    "\n",
    "    def get_outlayer_area(self, current_val):\n",
    "        current_crop_img, current_restrict_area = get_crop_by_pixel_val(self.input_3d_img, current_val,\n",
    "                                                                        boundary_extend=self.boundary_extend,\n",
    "                                                                        crop_another_3d_img_by_the_way=self.restrict_area_3d)\n",
    "        current_crop_img_onehot = np.array(current_crop_img==current_val, dtype=np.int8)\n",
    "        current_crop_img_onehot_outlayer = get_outlayer_of_a_3d_shape(current_crop_img_onehot)\n",
    "\n",
    "        assert current_crop_img_onehot_outlayer.shape == current_restrict_area.shape\n",
    "\n",
    "        current_crop_img_onehot_outlayer[current_restrict_area>0]=0\n",
    "        current_crop_outlayer_area = np.sum(current_crop_img_onehot_outlayer)\n",
    "\n",
    "        return current_crop_outlayer_area\n",
    "\n",
    "    def regionQuery(self, current_val):\n",
    "        current_crop_img, current_restrict_area = get_crop_by_pixel_val(self.input_3d_img, current_val,\n",
    "                                                                        boundary_extend=self.boundary_extend,\n",
    "                                                                        crop_another_3d_img_by_the_way=self.restrict_area_3d)\n",
    "\n",
    "        current_crop_img_onehot = np.array(current_crop_img==current_val, dtype=np.int8)\n",
    "        current_crop_img_onehot_outlayer = get_outlayer_of_a_3d_shape(current_crop_img_onehot)\n",
    "\n",
    "        assert current_crop_img_onehot_outlayer.shape == current_restrict_area.shape\n",
    "\n",
    "        current_crop_img_onehot_outlayer[current_restrict_area>0]=0\n",
    "        current_crop_outlayer_area = np.sum(current_crop_img_onehot_outlayer)\n",
    "\n",
    "        neighbor_vals, neighbor_val_counts = np.unique(current_crop_img[current_crop_img_onehot_outlayer>0], return_counts=True)\n",
    "        neighbor_val_counts = neighbor_val_counts[neighbor_vals>0]\n",
    "        neighbor_vals = neighbor_vals[neighbor_vals>0]\n",
    "\n",
    "        print(\"current_crop_outlayer_area: \"+str(current_crop_outlayer_area))\n",
    "\n",
    "        valid_neighbor_vals = self.neighborCheck(neighbor_vals, neighbor_val_counts, current_crop_outlayer_area)\n",
    "\n",
    "\n",
    "        print(\"valid_neighbor_vals: \"+str(valid_neighbor_vals))\n",
    "\n",
    "        return valid_neighbor_vals\n",
    "\n",
    "    def neighborCheck(self, neighbor_vals, neighbor_val_counts, current_crop_outlayer_area):\n",
    "        neighbor_val_counts = neighbor_val_counts[neighbor_vals>0]\n",
    "        neighbor_vals = neighbor_vals[neighbor_vals>0]\n",
    "\n",
    "        valid_neighbor_vals_dict = {}\n",
    "        for idx, neighbor_val in enumerate(neighbor_vals):\n",
    "            print(\"touching_area: \"+str(neighbor_val_counts[idx]), end=\"\\r\")\n",
    "            valid_neighbor_vals_dict[neighbor_val] = neighbor_val_counts[idx]\n",
    "\n",
    "        # double_checked_valid_neighbor_vals = []\n",
    "        # for valid_neighbor_val in valid_neighbor_vals_dict.keys():\n",
    "        #    if self.val_labels[valid_neighbor_val]==self.UN_PROCESSED or \\\n",
    "        #     self.val_labels[valid_neighbor_val]==self.LONELY_POINT:\n",
    "        #        double_checked_valid_neighbor_vals.append(valid_neighbor_val)\n",
    "\n",
    "        return valid_neighbor_vals_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "class Super_Vox_To_Graph():\n",
    "    def __init__(self, boundary_extend=2):\n",
    "        super(Super_Vox_To_Graph, self).__init__\n",
    "        self.boundary_extend = boundary_extend\n",
    "\n",
    "        self.UN_PROCESSED = 0\n",
    "        self.LONELY_POINT = -1\n",
    "        self.A_LARGE_NUM = 100000000\n",
    "\n",
    "    def get_neighbors_and_touching_area(self, input_3d_img, restrict_area_3d=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_3d_img\n",
    "        restrict_area_3d\n",
    "\n",
    "        Returns numpy array with each column representing two super voxels touching\n",
    "                -> shape: supervoxel_1, neighbor_1, touching_area(between supervoxel_1 and neighbor_1)\n",
    "                          supervoxel_1, neighbor_2, touching_area(between supervoxel_1 and neighbor_2)\n",
    "                          ...\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        self.input_3d_img = input_3d_img\n",
    "\n",
    "        if restrict_area_3d is None:\n",
    "            self.restrict_area_3d = np.array(input_3d_img==0, dtype=np.int8)\n",
    "        else:\n",
    "            self.restrict_area_3d = restrict_area_3d\n",
    "\n",
    "        unique_vals, unique_val_counts = np.unique(self.input_3d_img, return_counts=True)\n",
    "\n",
    "        unique_val_counts = unique_val_counts[unique_vals>0]\n",
    "        unique_vals = unique_vals[unique_vals>0]\n",
    "        sort_locs = np.argsort(unique_val_counts)[::-1]\n",
    "\n",
    "        self.unique_vals = unique_vals[sort_locs]\n",
    "\n",
    "        self.val_labels = dict()\n",
    "        for unique_val in self.unique_vals:\n",
    "            self.val_labels[unique_val] = self.UN_PROCESSED\n",
    "\n",
    "        self.val_outlayer_area = dict()\n",
    "        for idx, unique_val in enumerate(self.unique_vals):\n",
    "            # print(\"get val_outlayer area of all vals: \"+str(idx/len(self.unique_vals)))\n",
    "            self.val_outlayer_area[unique_val] = self.A_LARGE_NUM\n",
    "\n",
    "        \"\"\"\n",
    "        neighborhoods:\n",
    "        np array:\n",
    "        supervoxel1, neighbor_1, touching_area\n",
    "        supervoxel1, neighbor_2, touching_area\n",
    "        ...\n",
    "        \"\"\"\n",
    "        neighborhoods = []\n",
    "        for idx, current_val in enumerate(self.unique_vals):\n",
    "            # print('processing: '+str(idx/len(self.unique_vals))+' pixel val: '+str(current_val))\n",
    "            #if self.val_labels[current_val]!=self.UN_PROCESSED:\n",
    "            #    continue\n",
    "            valid_neighbor_vals = self.regionQuery(current_val)\n",
    "            if len(valid_neighbor_vals) != 0:\n",
    "                neighborhoods.append(valid_neighbor_vals)\n",
    "            # if len(valid_neighbor_vals)>0:\n",
    "            #     # print('Assign label '+str(current_val)+' to current val\\'s neighbors: '+str(valid_neighbor_vals))\n",
    "            #    self.val_labels[current_val] = current_val\n",
    "            #    self.growCluster(valid_neighbor_vals, current_val)\n",
    "            # else:\n",
    "            #    self.val_labels[current_val] = self.LONELY_POINT\n",
    "\n",
    "        # self.output_3d_img = self.input_3d_img\n",
    "        neighborhoods = np.vstack(neighborhoods)\n",
    "\n",
    "        # remove duplicate combinations\n",
    "        neighborhoods_sorted_pairs = neighborhoods[:,0:2][:, neighborhoods[:,0:2][0, :].argsort()]\n",
    "\n",
    "\n",
    "        ind = np.argsort(neighborhoods[:,0:2], axis=1)\n",
    "        neighborhoods_sorted_pairs = np.take_along_axis(neighborhoods[:,0:2], ind, axis=1)\n",
    "\n",
    "        _, indices_unique = np.unique(neighborhoods_sorted_pairs, axis=0, return_index=True)\n",
    "\n",
    "        neighborhoods_deduplicated = neighborhoods[indices_unique]\n",
    "\n",
    "        return neighborhoods_deduplicated\n",
    "\n",
    "    def get_outlayer_area(self, current_val):\n",
    "        current_crop_img, current_restrict_area = get_crop_by_pixel_val(self.input_3d_img, current_val,\n",
    "                                                                        boundary_extend=self.boundary_extend,\n",
    "                                                                        crop_another_3d_img_by_the_way=self.restrict_area_3d)\n",
    "        current_crop_img_onehot = np.array(current_crop_img==current_val, dtype=np.int8)\n",
    "        current_crop_img_onehot_outlayer = get_outlayer_of_a_3d_shape(current_crop_img_onehot)\n",
    "\n",
    "        assert current_crop_img_onehot_outlayer.shape == current_restrict_area.shape\n",
    "\n",
    "        current_crop_img_onehot_outlayer[current_restrict_area>0]=0\n",
    "        current_crop_outlayer_area = np.sum(current_crop_img_onehot_outlayer)\n",
    "\n",
    "        return current_crop_outlayer_area\n",
    "\n",
    "    def regionQuery(self, current_val):\n",
    "        current_crop_img, current_restrict_area = get_crop_by_pixel_val(self.input_3d_img, current_val,\n",
    "                                                                        boundary_extend=self.boundary_extend,\n",
    "                                                                        crop_another_3d_img_by_the_way=self.restrict_area_3d)\n",
    "\n",
    "        current_crop_img_onehot = np.array(current_crop_img==current_val, dtype=np.int8)\n",
    "        current_crop_img_onehot_outlayer = get_outlayer_of_a_3d_shape(current_crop_img_onehot)\n",
    "\n",
    "        assert current_crop_img_onehot_outlayer.shape == current_restrict_area.shape\n",
    "\n",
    "        current_crop_img_onehot_outlayer[current_restrict_area>0]=0\n",
    "        current_crop_outlayer_area = np.sum(current_crop_img_onehot_outlayer)\n",
    "\n",
    "        neighbor_vals, neighbor_val_counts = np.unique(current_crop_img[current_crop_img_onehot_outlayer>0], return_counts=True)\n",
    "        neighbor_val_counts = neighbor_val_counts[neighbor_vals>0]\n",
    "        neighbor_vals = neighbor_vals[neighbor_vals>0]\n",
    "\n",
    "        # print(\"current_crop_outlayer_area: \"+str(current_crop_outlayer_area))\n",
    "\n",
    "        valid_neighbor_vals = self.neighborCheck(current_val, neighbor_vals, neighbor_val_counts, current_crop_outlayer_area)\n",
    "\n",
    "\n",
    "        # print(\"valid_neighbor_vals: \"+str(valid_neighbor_vals))\n",
    "\n",
    "        return valid_neighbor_vals\n",
    "\n",
    "    def neighborCheck(self, current_val, neighbor_vals, neighbor_val_counts, current_crop_outlayer_area):\n",
    "        neighbor_val_counts = neighbor_val_counts[neighbor_vals>0]\n",
    "        neighbor_vals = neighbor_vals[neighbor_vals>0]\n",
    "\n",
    "        valid_neighbor_vals = np.empty((len(neighbor_vals), 3))\n",
    "        valid_neighbor_vals[:,0] = current_val\n",
    "        for idx, neighbor_val in enumerate(neighbor_vals):\n",
    "            # print(\"touching_area: \"+str(neighbor_val_counts[idx]), end=\"\\r\")\n",
    "            # valid_neighbor_vals_dict[neighbor_val] = neighbor_val_counts[idx]\n",
    "            valid_neighbor_vals[idx, 1] = neighbor_val\n",
    "            valid_neighbor_vals[idx, 2] = neighbor_val_counts[idx]\n",
    "\n",
    "        # double_checked_valid_neighbor_vals = []\n",
    "        # for valid_neighbor_val in valid_neighbor_vals_dict.keys():\n",
    "        #    if self.val_labels[valid_neighbor_val]==self.UN_PROCESSED or \\\n",
    "        #     self.val_labels[valid_neighbor_val]==self.LONELY_POINT:\n",
    "        #        double_checked_valid_neighbor_vals.append(valid_neighbor_val)\n",
    "\n",
    "        return valid_neighbor_vals\n",
    "\n",
    "    def add_ground_truth_node_labels(self, input_3d_img, groundtruth_img, neighbors_and_touching_area):\n",
    "        # add ground truth column to neighbors_and_touching_area matrix\n",
    "        neighbors_and_touching_area = np.c_[(neighbors_and_touching_area,\n",
    "                                                np.zeros(len(neighbors_and_touching_area)))]\n",
    "        unique_values = np.unique(neighbors_and_touching_area[:,0])\n",
    "\n",
    "        # get the ground truth cell label for each super voxel\n",
    "        groundtruth_labels = {}\n",
    "        for idx, value in enumerate(unique_values):\n",
    "            # get values of groundtruth that overlap with each supervoxel\n",
    "            overlapping_voxels = groundtruth_img[np.where(input_3d_img == value)]\n",
    "            # get the most occuring groundtruth voxel label for each supervoxel\n",
    "            gt_label = np.bincount(overlapping_voxels.astype(int)).argmax()\n",
    "\n",
    "            groundtruth_labels[value] = gt_label\n",
    "\n",
    "        # set ground 4th column of neighbors_and_touching_area to 1\n",
    "        # if both supervoxels have the same groundtruth cell label, 0 otherwise\n",
    "        for idx, col in enumerate(neighbors_and_touching_area):\n",
    "            if groundtruth_labels[col[0]] == groundtruth_labels[col[1]]:\n",
    "                neighbors_and_touching_area[idx, 3] = 1\n",
    "\n",
    "        return neighbors_and_touching_area"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "super_vox_to_graph = Super_Vox_To_Graph()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951\n",
      "[1238 1117  623 ...   33  628  843]\n",
      "3720\n",
      "1860\n"
     ]
    }
   ],
   "source": [
    "neighbors = super_vox_to_graph.get_neighbors_and_touching_area(seg_foreground_super_voxel_by_ws)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#seg_foreground_super_voxel_by_ws\n",
    "#hand_seg\n",
    "len(neighbors)\n",
    "for n in neighbors:\n",
    "    #print(f\"n = {n}\")\n",
    "    x = neighbors[np.where(np.logical_and(neighbors[:,0] == n[1], neighbors[:,1] == n[0]))]\n",
    "    print(f\"x = {x}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "neighbors_with_gt = super_vox_to_graph.add_ground_truth_node_labels(seg_foreground_super_voxel_by_ws,\n",
    "                                                                    hand_seg,\n",
    "                                                                    neighbors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.239e+03, 1.326e+03, 1.000e+00, 0.000e+00],\n       [1.239e+03, 1.374e+03, 3.000e+00, 1.000e+00],\n       [5.070e+02, 2.340e+02, 2.500e+01, 1.000e+00],\n       ...,\n       [1.409e+03, 1.429e+03, 1.000e+00, 1.000e+00],\n       [1.655e+03, 1.637e+03, 1.000e+00, 1.000e+00],\n       [1.291e+03, 1.292e+03, 1.000e+00, 1.000e+00]])"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_with_gt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "a = np.array([[8,3],\n",
    "              [7,4],\n",
    "              [9,0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[7, 4],\n        [8, 3],\n        [9, 0]]),\n array([1, 0, 2]))"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a, axis=0, return_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 2.000e+00]\n",
      " [1.000e+00 5.000e+00]\n",
      " [1.000e+00 8.000e+00]\n",
      " ...\n",
      " [1.949e+03 1.943e+03]\n",
      " [1.950e+03 1.888e+03]\n",
      " [1.950e+03 1.899e+03]]\n",
      "3720\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "neighbors_2 = neighbors[:,0:2]\n",
    "print(neighbors_2)\n",
    "\n",
    "ind = np.argsort(neighbors_2, axis=1)\n",
    "neighbors_2 = np.take_along_axis(neighbors_2, ind, axis=1)\n",
    "print(len(neighbors_2))\n",
    "un, indices_unique = np.unique(neighbors_2, axis=1, return_index=True)\n",
    "neighbors_2 = neighbors_2\n",
    "print(len(indices_unique))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.000e+00, 2.000e+00],\n       [1.000e+00, 5.000e+00],\n       [1.000e+00, 8.000e+00],\n       ...,\n       [1.943e+03, 1.949e+03],\n       [1.888e+03, 1.950e+03],\n       [1.899e+03, 1.950e+03]])"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}