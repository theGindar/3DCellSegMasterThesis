{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from func.run_pipeline_super_vox import get_outlayer_of_a_3d_shape, get_crop_by_pixel_val\n",
    "from func.ultis import load_obj\n",
    "\n",
    "from func.graph_learning import SuperVoxToNxGraph, VoxelGraphDataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load graphs\n",
    "from func.ultis import load_obj\n",
    "\n",
    "graphs = load_obj(\"graphs_dataset_train\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CellSeg3D_torch/lib/python3.8/site-packages/dgl/backend/pytorch/tensor.py:40: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  return th.as_tensor(data, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405\n",
      "torch.Size([1405, 3])\n",
      "torch.Size([5327, 1])\n",
      "888\n",
      "torch.Size([888, 3])\n",
      "torch.Size([3534, 1])\n",
      "1652\n",
      "torch.Size([1652, 3])\n",
      "torch.Size([6150, 1])\n",
      "1491\n",
      "torch.Size([1491, 3])\n",
      "torch.Size([5661, 1])\n",
      "1316\n",
      "torch.Size([1316, 3])\n",
      "torch.Size([4952, 1])\n",
      "978\n",
      "torch.Size([978, 3])\n",
      "torch.Size([4336, 1])\n",
      "1544\n",
      "torch.Size([1544, 3])\n",
      "torch.Size([5952, 1])\n",
      "1814\n",
      "torch.Size([1814, 3])\n",
      "torch.Size([7458, 1])\n",
      "1749\n",
      "torch.Size([1749, 3])\n",
      "torch.Size([7247, 1])\n",
      "1541\n",
      "torch.Size([1541, 3])\n",
      "torch.Size([6003, 1])\n",
      "1416\n",
      "torch.Size([1416, 3])\n",
      "torch.Size([5146, 1])\n",
      "1766\n",
      "torch.Size([1766, 3])\n",
      "torch.Size([6972, 1])\n",
      "1235\n",
      "torch.Size([1235, 3])\n",
      "torch.Size([4581, 1])\n",
      "1654\n",
      "torch.Size([1654, 3])\n",
      "torch.Size([6612, 1])\n",
      "1131\n",
      "torch.Size([1131, 3])\n",
      "torch.Size([4471, 1])\n",
      "1397\n",
      "torch.Size([1397, 3])\n",
      "torch.Size([5481, 1])\n",
      "1510\n",
      "torch.Size([1510, 3])\n",
      "torch.Size([5524, 1])\n",
      "1253\n",
      "torch.Size([1253, 3])\n",
      "torch.Size([4667, 1])\n",
      "1309\n",
      "torch.Size([1309, 3])\n",
      "torch.Size([4693, 1])\n",
      "1587\n",
      "torch.Size([1587, 3])\n",
      "torch.Size([5967, 1])\n",
      "913\n",
      "torch.Size([913, 3])\n",
      "torch.Size([3719, 1])\n",
      "1684\n",
      "torch.Size([1684, 3])\n",
      "torch.Size([6424, 1])\n",
      "1636\n",
      "torch.Size([1636, 3])\n",
      "torch.Size([6814, 1])\n",
      "1526\n",
      "torch.Size([1526, 3])\n",
      "torch.Size([6218, 1])\n",
      "1436\n",
      "torch.Size([1436, 3])\n",
      "torch.Size([5316, 1])\n",
      "1435\n",
      "torch.Size([1435, 3])\n",
      "torch.Size([5421, 1])\n",
      "1074\n",
      "torch.Size([1074, 3])\n",
      "torch.Size([4434, 1])\n",
      "1469\n",
      "torch.Size([1469, 3])\n",
      "torch.Size([5647, 1])\n",
      "1159\n",
      "torch.Size([1159, 3])\n",
      "torch.Size([4509, 1])\n",
      "1656\n",
      "torch.Size([1656, 3])\n",
      "torch.Size([6694, 1])\n",
      "2008\n",
      "torch.Size([2008, 3])\n",
      "torch.Size([8044, 1])\n",
      "1262\n",
      "torch.Size([1262, 3])\n",
      "torch.Size([4810, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = VoxelGraphDataset(graphs)\n",
    "\n",
    "g = dataset[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO probably should normalize features!!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from func.graph_models import GCN, GCN_2\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "model = GCN(3, num_classes=2)\n",
    "CELoss = nn.CrossEntropyLoss()\n",
    "\n",
    "# training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "best_val_acc = 0\n",
    "\n",
    "\n",
    "\n",
    "# features = g.ndata['feat']\n",
    "# labels = g.ndata['label']\n",
    "# train_mask = g.ndata['train_mask']\n",
    "# val_mask = g.ndata['val_mask']\n",
    "\n",
    "# calculate weights for loss\n",
    "\"\"\"\n",
    "pos_weights = []\n",
    "neg_weights = []\n",
    "for graph_number in range(len(dataset)):\n",
    "    sample_graph = dataset[graph_number]\n",
    "    labels = sample_graph.ndata['label']\n",
    "    # create class weights\n",
    "    number_positives = torch.count_nonzero(labels)\n",
    "    positive_weight = 1 - (number_positives / len(labels))\n",
    "    negative_weight = 1 - positive_weight\n",
    "\n",
    "    pos_weights.append(positive_weight.item())\n",
    "    neg_weights.append(negative_weight.item())\n",
    "weights = torch.tensor([mean(neg_weights), mean(pos_weights)])\n",
    "print(f\"weights: {weights}\")\n",
    "\"\"\"\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "f1 = F1Score(num_classes=2, average='weighted')\n",
    "\n",
    "epoch_loss = []\n",
    "epoch_val_loss = []\n",
    "epoch_accuracy = []\n",
    "\n",
    "epoch_f1score = []\n",
    "epoch_f1score_val = []\n",
    "\n",
    "epoch_accuracy_val = []\n",
    "# best_val_acc = 0\n",
    "best_val_loss = 1000\n",
    "\n",
    "for e in range(500):\n",
    "    # get random elements for batch\n",
    "    #graphs_numbers_list = range(0, len(dataset))\n",
    "    #rand_graph_numbers = random.sample(graphs_numbers_list, len(dataset))\n",
    "    for graph_number in range(len(dataset)):\n",
    "    #for graph_number in range(1):\n",
    "    #for graph_number in rand_graph_numbers:\n",
    "        # Forward\n",
    "        model.train()\n",
    "        sample_graph = dataset[graph_number]\n",
    "        features = sample_graph.ndata['feat']\n",
    "        labels = sample_graph.ndata['label']\n",
    "        train_mask = sample_graph.ndata['train_mask']\n",
    "        val_mask = sample_graph.ndata['val_mask']\n",
    "\n",
    "        # create class weights\n",
    "        number_positives = torch.count_nonzero(labels)\n",
    "        percentage_positives = number_positives / len(labels)\n",
    "        percentage_negatives = 1 - percentage_positives\n",
    "\n",
    "        weights = torch.tensor([1 - percentage_negatives, 1 - percentage_positives])\n",
    "        #weights = torch.tensor([0.95, 0.05])\n",
    "        #print(weights)\n",
    "\n",
    "        CELoss = nn.CrossEntropyLoss(weight=weights)\n",
    "        train_mask = sample_graph.ndata['train_mask']\n",
    "        val_mask = sample_graph.ndata['val_mask']\n",
    "        logits = model(sample_graph, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = CELoss(logits[train_mask], labels[train_mask])\n",
    "\n",
    "\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        #print(loss)\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "\n",
    "        train_f1_score = f1(pred[train_mask], labels[train_mask])\n",
    "        val_f1_score = f1(pred[val_mask], labels[val_mask])\n",
    "\n",
    "\n",
    "        epoch_accuracy.append(train_acc.item())\n",
    "        epoch_accuracy_val.append(val_acc.item())\n",
    "\n",
    "        epoch_f1score.append(train_f1_score.item())\n",
    "        epoch_f1score_val.append(val_f1_score.item())\n",
    "\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(sample_graph, features)\n",
    "            val_loss = CELoss(logits[val_mask], labels[val_mask])\n",
    "            epoch_val_loss.append(val_loss.item())\n",
    "        model.train()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {:.5f}, val loss: {:.5f}, accuracy: {:.3f}, val accuracy: {:.3f}, f1score: {:.3f}, val f1score: {:.3f}'.format(\n",
    "            e, mean(epoch_loss), mean(epoch_val_loss), mean(epoch_accuracy), mean(epoch_accuracy_val), mean(epoch_f1score), mean(epoch_f1score_val)))\n",
    "\n",
    "        #if mean(epoch_accuracy_val) >= best_val_acc:\n",
    "        if mean(epoch_val_loss) <= best_val_loss:\n",
    "            print(\"new best val loss\")\n",
    "            torch.save(model.state_dict(), \"output/graph_model.pt\")\n",
    "            best_val_loss = mean(epoch_val_loss)\n",
    "        epoch_loss = []\n",
    "        epoch_val_loss = []\n",
    "        epoch_accuracy = []\n",
    "\n",
    "        epoch_accuracy_val = []\n",
    "        epoch_f1score_val = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CellSeg3D_torch/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.72064, val loss: 0.70695, accuracy: 0.530, val accuracy: 0.507, f1score: 0.625, val f1score: 0.588\n",
      "new best val loss\n",
      "In epoch 5, loss: 0.68388, val loss: 0.68478, accuracy: 0.699, val accuracy: 0.678, f1score: 0.748, val f1score: 0.743\n",
      "new best val loss\n",
      "In epoch 10, loss: 0.65818, val loss: 0.64642, accuracy: 0.690, val accuracy: 0.664, f1score: 0.756, val f1score: 0.734\n",
      "new best val loss\n",
      "In epoch 15, loss: 0.65033, val loss: 0.62937, accuracy: 0.687, val accuracy: 0.653, f1score: 0.759, val f1score: 0.725\n",
      "new best val loss\n",
      "In epoch 20, loss: 0.64364, val loss: 0.61894, accuracy: 0.702, val accuracy: 0.663, f1score: 0.763, val f1score: 0.732\n",
      "new best val loss\n",
      "In epoch 25, loss: 0.63938, val loss: 0.61080, accuracy: 0.718, val accuracy: 0.678, f1score: 0.767, val f1score: 0.743\n",
      "new best val loss\n",
      "In epoch 30, loss: 0.63775, val loss: 0.60511, accuracy: 0.731, val accuracy: 0.691, f1score: 0.772, val f1score: 0.753\n",
      "new best val loss\n",
      "In epoch 35, loss: 0.63710, val loss: 0.60256, accuracy: 0.744, val accuracy: 0.705, f1score: 0.776, val f1score: 0.763\n",
      "new best val loss\n",
      "In epoch 40, loss: 0.63545, val loss: 0.59945, accuracy: 0.754, val accuracy: 0.718, f1score: 0.781, val f1score: 0.773\n",
      "new best val loss\n",
      "In epoch 45, loss: 0.63327, val loss: 0.59600, accuracy: 0.759, val accuracy: 0.717, f1score: 0.784, val f1score: 0.773\n",
      "new best val loss\n",
      "In epoch 50, loss: 0.63350, val loss: 0.59505, accuracy: 0.763, val accuracy: 0.722, f1score: 0.788, val f1score: 0.776\n",
      "new best val loss\n",
      "In epoch 55, loss: 0.63307, val loss: 0.59411, accuracy: 0.768, val accuracy: 0.730, f1score: 0.791, val f1score: 0.782\n",
      "new best val loss\n",
      "In epoch 60, loss: 0.63400, val loss: 0.59400, accuracy: 0.770, val accuracy: 0.735, f1score: 0.793, val f1score: 0.786\n",
      "new best val loss\n",
      "In epoch 65, loss: 0.63420, val loss: 0.59319, accuracy: 0.775, val accuracy: 0.736, f1score: 0.796, val f1score: 0.787\n",
      "new best val loss\n",
      "In epoch 70, loss: 0.63418, val loss: 0.59263, accuracy: 0.775, val accuracy: 0.733, f1score: 0.798, val f1score: 0.784\n",
      "new best val loss\n",
      "In epoch 75, loss: 0.63298, val loss: 0.59215, accuracy: 0.778, val accuracy: 0.740, f1score: 0.800, val f1score: 0.790\n",
      "new best val loss\n",
      "In epoch 80, loss: 0.63423, val loss: 0.59203, accuracy: 0.777, val accuracy: 0.738, f1score: 0.801, val f1score: 0.788\n",
      "new best val loss\n",
      "In epoch 85, loss: 0.63316, val loss: 0.59179, accuracy: 0.774, val accuracy: 0.739, f1score: 0.803, val f1score: 0.788\n",
      "new best val loss\n",
      "In epoch 90, loss: 0.63421, val loss: 0.59220, accuracy: 0.778, val accuracy: 0.741, f1score: 0.804, val f1score: 0.790\n",
      "In epoch 95, loss: 0.63537, val loss: 0.59193, accuracy: 0.778, val accuracy: 0.739, f1score: 0.805, val f1score: 0.788\n",
      "In epoch 100, loss: 0.63445, val loss: 0.59124, accuracy: 0.779, val accuracy: 0.741, f1score: 0.807, val f1score: 0.790\n",
      "new best val loss\n",
      "In epoch 105, loss: 0.63297, val loss: 0.59132, accuracy: 0.777, val accuracy: 0.739, f1score: 0.807, val f1score: 0.788\n",
      "In epoch 110, loss: 0.63249, val loss: 0.59103, accuracy: 0.780, val accuracy: 0.737, f1score: 0.808, val f1score: 0.787\n",
      "new best val loss\n",
      "In epoch 115, loss: 0.63326, val loss: 0.59111, accuracy: 0.779, val accuracy: 0.740, f1score: 0.809, val f1score: 0.789\n",
      "In epoch 120, loss: 0.63287, val loss: 0.59089, accuracy: 0.780, val accuracy: 0.741, f1score: 0.810, val f1score: 0.791\n",
      "new best val loss\n",
      "In epoch 125, loss: 0.63484, val loss: 0.59181, accuracy: 0.781, val accuracy: 0.740, f1score: 0.811, val f1score: 0.789\n",
      "In epoch 130, loss: 0.63429, val loss: 0.59218, accuracy: 0.780, val accuracy: 0.743, f1score: 0.812, val f1score: 0.791\n",
      "In epoch 135, loss: 0.63416, val loss: 0.59164, accuracy: 0.780, val accuracy: 0.741, f1score: 0.812, val f1score: 0.790\n",
      "In epoch 140, loss: 0.63270, val loss: 0.59134, accuracy: 0.780, val accuracy: 0.741, f1score: 0.813, val f1score: 0.790\n",
      "In epoch 145, loss: 0.63332, val loss: 0.59175, accuracy: 0.779, val accuracy: 0.742, f1score: 0.813, val f1score: 0.790\n",
      "In epoch 150, loss: 0.63575, val loss: 0.59211, accuracy: 0.782, val accuracy: 0.745, f1score: 0.814, val f1score: 0.794\n",
      "In epoch 155, loss: 0.63503, val loss: 0.59291, accuracy: 0.783, val accuracy: 0.748, f1score: 0.814, val f1score: 0.795\n",
      "In epoch 160, loss: 0.63218, val loss: 0.59098, accuracy: 0.781, val accuracy: 0.744, f1score: 0.815, val f1score: 0.792\n",
      "In epoch 165, loss: 0.63298, val loss: 0.59078, accuracy: 0.781, val accuracy: 0.746, f1score: 0.815, val f1score: 0.794\n",
      "new best val loss\n",
      "In epoch 170, loss: 0.63400, val loss: 0.59112, accuracy: 0.783, val accuracy: 0.746, f1score: 0.816, val f1score: 0.793\n",
      "In epoch 175, loss: 0.63326, val loss: 0.59069, accuracy: 0.783, val accuracy: 0.742, f1score: 0.816, val f1score: 0.791\n",
      "new best val loss\n",
      "In epoch 180, loss: 0.63338, val loss: 0.59162, accuracy: 0.782, val accuracy: 0.745, f1score: 0.817, val f1score: 0.792\n",
      "In epoch 185, loss: 0.63499, val loss: 0.59186, accuracy: 0.780, val accuracy: 0.740, f1score: 0.817, val f1score: 0.789\n",
      "In epoch 190, loss: 0.63244, val loss: 0.59090, accuracy: 0.779, val accuracy: 0.741, f1score: 0.817, val f1score: 0.790\n",
      "In epoch 195, loss: 0.63366, val loss: 0.59061, accuracy: 0.775, val accuracy: 0.737, f1score: 0.817, val f1score: 0.787\n",
      "new best val loss\n",
      "In epoch 200, loss: 0.63287, val loss: 0.59119, accuracy: 0.778, val accuracy: 0.743, f1score: 0.818, val f1score: 0.791\n",
      "In epoch 205, loss: 0.63269, val loss: 0.59117, accuracy: 0.781, val accuracy: 0.743, f1score: 0.818, val f1score: 0.791\n",
      "In epoch 210, loss: 0.63207, val loss: 0.59047, accuracy: 0.779, val accuracy: 0.741, f1score: 0.818, val f1score: 0.790\n",
      "new best val loss\n",
      "In epoch 215, loss: 0.63365, val loss: 0.59138, accuracy: 0.781, val accuracy: 0.738, f1score: 0.819, val f1score: 0.788\n",
      "In epoch 220, loss: 0.63295, val loss: 0.59107, accuracy: 0.781, val accuracy: 0.746, f1score: 0.819, val f1score: 0.793\n",
      "In epoch 225, loss: 0.63235, val loss: 0.59097, accuracy: 0.780, val accuracy: 0.742, f1score: 0.819, val f1score: 0.791\n",
      "In epoch 230, loss: 0.63248, val loss: 0.59070, accuracy: 0.782, val accuracy: 0.742, f1score: 0.819, val f1score: 0.790\n",
      "In epoch 235, loss: 0.63364, val loss: 0.59162, accuracy: 0.784, val accuracy: 0.747, f1score: 0.820, val f1score: 0.794\n",
      "In epoch 240, loss: 0.63337, val loss: 0.59072, accuracy: 0.782, val accuracy: 0.743, f1score: 0.820, val f1score: 0.791\n",
      "In epoch 245, loss: 0.63473, val loss: 0.59095, accuracy: 0.780, val accuracy: 0.739, f1score: 0.820, val f1score: 0.789\n",
      "In epoch 250, loss: 0.63381, val loss: 0.59169, accuracy: 0.780, val accuracy: 0.741, f1score: 0.820, val f1score: 0.790\n",
      "In epoch 255, loss: 0.63076, val loss: 0.59092, accuracy: 0.780, val accuracy: 0.742, f1score: 0.820, val f1score: 0.791\n",
      "In epoch 260, loss: 0.63238, val loss: 0.59007, accuracy: 0.780, val accuracy: 0.744, f1score: 0.820, val f1score: 0.792\n",
      "new best val loss\n",
      "In epoch 265, loss: 0.63372, val loss: 0.59112, accuracy: 0.779, val accuracy: 0.743, f1score: 0.821, val f1score: 0.792\n",
      "In epoch 270, loss: 0.63369, val loss: 0.59130, accuracy: 0.780, val accuracy: 0.740, f1score: 0.821, val f1score: 0.789\n",
      "In epoch 275, loss: 0.63393, val loss: 0.59161, accuracy: 0.782, val accuracy: 0.745, f1score: 0.821, val f1score: 0.793\n",
      "In epoch 280, loss: 0.63381, val loss: 0.59166, accuracy: 0.780, val accuracy: 0.743, f1score: 0.821, val f1score: 0.791\n",
      "In epoch 285, loss: 0.63236, val loss: 0.59072, accuracy: 0.779, val accuracy: 0.740, f1score: 0.821, val f1score: 0.790\n",
      "In epoch 290, loss: 0.63398, val loss: 0.59134, accuracy: 0.783, val accuracy: 0.742, f1score: 0.821, val f1score: 0.791\n",
      "In epoch 295, loss: 0.63382, val loss: 0.59073, accuracy: 0.780, val accuracy: 0.738, f1score: 0.821, val f1score: 0.788\n",
      "In epoch 300, loss: 0.63472, val loss: 0.59222, accuracy: 0.781, val accuracy: 0.743, f1score: 0.822, val f1score: 0.792\n",
      "In epoch 305, loss: 0.63356, val loss: 0.59149, accuracy: 0.779, val accuracy: 0.741, f1score: 0.822, val f1score: 0.790\n",
      "In epoch 310, loss: 0.63335, val loss: 0.59104, accuracy: 0.781, val accuracy: 0.738, f1score: 0.822, val f1score: 0.788\n",
      "In epoch 315, loss: 0.63412, val loss: 0.59124, accuracy: 0.778, val accuracy: 0.738, f1score: 0.822, val f1score: 0.787\n",
      "In epoch 320, loss: 0.63152, val loss: 0.59021, accuracy: 0.777, val accuracy: 0.737, f1score: 0.822, val f1score: 0.788\n",
      "In epoch 325, loss: 0.63436, val loss: 0.59181, accuracy: 0.779, val accuracy: 0.739, f1score: 0.822, val f1score: 0.788\n",
      "In epoch 330, loss: 0.63302, val loss: 0.59082, accuracy: 0.779, val accuracy: 0.739, f1score: 0.822, val f1score: 0.788\n",
      "In epoch 335, loss: 0.63368, val loss: 0.59153, accuracy: 0.781, val accuracy: 0.742, f1score: 0.822, val f1score: 0.791\n",
      "In epoch 340, loss: 0.63627, val loss: 0.59225, accuracy: 0.783, val accuracy: 0.742, f1score: 0.822, val f1score: 0.791\n",
      "In epoch 345, loss: 0.63345, val loss: 0.59110, accuracy: 0.779, val accuracy: 0.741, f1score: 0.823, val f1score: 0.790\n",
      "In epoch 350, loss: 0.63330, val loss: 0.59100, accuracy: 0.781, val accuracy: 0.743, f1score: 0.823, val f1score: 0.792\n",
      "In epoch 355, loss: 0.63439, val loss: 0.59143, accuracy: 0.782, val accuracy: 0.740, f1score: 0.823, val f1score: 0.789\n",
      "In epoch 360, loss: 0.63358, val loss: 0.59102, accuracy: 0.782, val accuracy: 0.742, f1score: 0.823, val f1score: 0.791\n",
      "In epoch 365, loss: 0.63292, val loss: 0.59103, accuracy: 0.781, val accuracy: 0.743, f1score: 0.823, val f1score: 0.791\n",
      "In epoch 370, loss: 0.63231, val loss: 0.59116, accuracy: 0.783, val accuracy: 0.743, f1score: 0.823, val f1score: 0.792\n",
      "In epoch 375, loss: 0.63129, val loss: 0.58957, accuracy: 0.782, val accuracy: 0.743, f1score: 0.823, val f1score: 0.792\n",
      "new best val loss\n",
      "In epoch 380, loss: 0.63320, val loss: 0.59106, accuracy: 0.783, val accuracy: 0.742, f1score: 0.823, val f1score: 0.791\n",
      "In epoch 385, loss: 0.63475, val loss: 0.59123, accuracy: 0.782, val accuracy: 0.742, f1score: 0.823, val f1score: 0.790\n",
      "In epoch 390, loss: 0.63328, val loss: 0.59095, accuracy: 0.782, val accuracy: 0.746, f1score: 0.823, val f1score: 0.793\n",
      "In epoch 395, loss: 0.63374, val loss: 0.59031, accuracy: 0.779, val accuracy: 0.739, f1score: 0.823, val f1score: 0.789\n",
      "In epoch 400, loss: 0.63435, val loss: 0.59138, accuracy: 0.783, val accuracy: 0.745, f1score: 0.824, val f1score: 0.793\n",
      "In epoch 405, loss: 0.63525, val loss: 0.59114, accuracy: 0.781, val accuracy: 0.743, f1score: 0.824, val f1score: 0.792\n",
      "In epoch 410, loss: 0.63479, val loss: 0.59158, accuracy: 0.782, val accuracy: 0.741, f1score: 0.824, val f1score: 0.790\n",
      "In epoch 415, loss: 0.63455, val loss: 0.59135, accuracy: 0.782, val accuracy: 0.743, f1score: 0.824, val f1score: 0.792\n",
      "In epoch 420, loss: 0.63211, val loss: 0.59031, accuracy: 0.779, val accuracy: 0.738, f1score: 0.824, val f1score: 0.788\n",
      "In epoch 425, loss: 0.63214, val loss: 0.59095, accuracy: 0.781, val accuracy: 0.742, f1score: 0.824, val f1score: 0.790\n",
      "In epoch 430, loss: 0.63491, val loss: 0.59210, accuracy: 0.781, val accuracy: 0.744, f1score: 0.824, val f1score: 0.792\n",
      "In epoch 435, loss: 0.63162, val loss: 0.58990, accuracy: 0.779, val accuracy: 0.736, f1score: 0.824, val f1score: 0.787\n",
      "In epoch 440, loss: 0.63256, val loss: 0.59090, accuracy: 0.778, val accuracy: 0.739, f1score: 0.824, val f1score: 0.789\n",
      "In epoch 445, loss: 0.63249, val loss: 0.59117, accuracy: 0.779, val accuracy: 0.739, f1score: 0.824, val f1score: 0.788\n",
      "In epoch 450, loss: 0.63376, val loss: 0.59111, accuracy: 0.780, val accuracy: 0.742, f1score: 0.824, val f1score: 0.791\n",
      "In epoch 455, loss: 0.63319, val loss: 0.59171, accuracy: 0.780, val accuracy: 0.742, f1score: 0.824, val f1score: 0.790\n",
      "In epoch 460, loss: 0.63399, val loss: 0.59191, accuracy: 0.780, val accuracy: 0.739, f1score: 0.824, val f1score: 0.788\n",
      "In epoch 465, loss: 0.63184, val loss: 0.59055, accuracy: 0.779, val accuracy: 0.738, f1score: 0.824, val f1score: 0.788\n",
      "In epoch 470, loss: 0.63160, val loss: 0.59105, accuracy: 0.779, val accuracy: 0.740, f1score: 0.824, val f1score: 0.789\n",
      "In epoch 475, loss: 0.63392, val loss: 0.59178, accuracy: 0.780, val accuracy: 0.744, f1score: 0.824, val f1score: 0.792\n",
      "In epoch 480, loss: 0.63412, val loss: 0.59156, accuracy: 0.782, val accuracy: 0.742, f1score: 0.824, val f1score: 0.791\n",
      "In epoch 485, loss: 0.63540, val loss: 0.59169, accuracy: 0.780, val accuracy: 0.741, f1score: 0.825, val f1score: 0.790\n",
      "In epoch 490, loss: 0.63303, val loss: 0.59091, accuracy: 0.780, val accuracy: 0.742, f1score: 0.825, val f1score: 0.791\n",
      "In epoch 495, loss: 0.63455, val loss: 0.59230, accuracy: 0.783, val accuracy: 0.742, f1score: 0.825, val f1score: 0.791\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from func.graph_models import GCN, GCN_2\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import dgl\n",
    "\n",
    "model = GCN(1, num_classes=2)\n",
    "CELoss = nn.CrossEntropyLoss()\n",
    "\n",
    "# training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "best_val_acc = 0\n",
    "\n",
    "\n",
    "\n",
    "# features = g.ndata['feat']\n",
    "# labels = g.ndata['label']\n",
    "# train_mask = g.ndata['train_mask']\n",
    "# val_mask = g.ndata['val_mask']\n",
    "\n",
    "# calculate weights for loss\n",
    "\"\"\"\n",
    "pos_weights = []\n",
    "neg_weights = []\n",
    "for graph_number in range(len(dataset)):\n",
    "    sample_graph = dataset[graph_number]\n",
    "    labels = sample_graph.ndata['label']\n",
    "    # create class weights\n",
    "    number_positives = torch.count_nonzero(labels)\n",
    "    positive_weight = 1 - (number_positives / len(labels))\n",
    "    negative_weight = 1 - positive_weight\n",
    "\n",
    "    pos_weights.append(positive_weight.item())\n",
    "    neg_weights.append(negative_weight.item())\n",
    "weights = torch.tensor([mean(neg_weights), mean(pos_weights)])\n",
    "print(f\"weights: {weights}\")\n",
    "\"\"\"\n",
    "\n",
    "# build one big graph\n",
    "graphs_list = []\n",
    "for i in range(len(dataset)):\n",
    "    graphs_list.append(dataset[i])\n",
    "\n",
    "large_g = dgl.batch(graphs_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "epoch_loss = []\n",
    "epoch_accuracy = []\n",
    "for e in range(1000):\n",
    "    # get random elements for batch\n",
    "    #graphs_numbers_list = range(0, len(dataset))\n",
    "    #rand_graph_numbers = random.sample(graphs_numbers_list, len(dataset))\n",
    "    sample_graph = large_g\n",
    "    features = sample_graph.ndata['feat']\n",
    "    labels = sample_graph.ndata['label']\n",
    "\n",
    "    # create class weights\n",
    "    number_positives = torch.count_nonzero(labels)\n",
    "    percentage_positives = number_positives / len(labels)\n",
    "    percentage_negatives = 1 - percentage_positives\n",
    "\n",
    "    weights = torch.tensor([1 - percentage_negatives, 1 - percentage_positives])\n",
    "    #weights = torch.tensor([0.95, 0.05])\n",
    "    #print(weights)\n",
    "\n",
    "    CELoss = nn.CrossEntropyLoss(weight=weights)\n",
    "    #train_mask = sample_graph.ndata['train_mask']\n",
    "    #val_mask = sample_graph.ndata['val_mask']\n",
    "    logits = model(sample_graph, features)\n",
    "\n",
    "    # Compute prediction\n",
    "    pred = logits.argmax(1)\n",
    "\n",
    "    # Compute loss\n",
    "    # Note that you should only compute the losses of the nodes in the training set.\n",
    "    loss = CELoss(logits, labels)\n",
    "    epoch_loss.append(loss.item())\n",
    "    #print(loss)\n",
    "    # Compute accuracy on training/validation/test\n",
    "    train_acc = (pred == labels).float().mean()\n",
    "    epoch_accuracy.append(train_acc.item())\n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        print('In epoch {}, loss: {:.3f}, accuracy: {:.3f}'.format(\n",
    "            e, mean(epoch_loss), mean(epoch_accuracy)))\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on GPU\n",
    "g = g.to('cuda')\n",
    "model = GCN(1, 16, dataset.num_classes).to('cuda')\n",
    "train(g, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes=1405, num_edges=5327,\n      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n      edata_schemes={'weight': Scheme(shape=(1,), dtype=torch.float64)})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1405, 3])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "g.ndata['feat'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(g, g.ndata['feat']).argmax(1).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = g.ndata['label']\n",
    "np.unique(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1315"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[labels==1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "90"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[labels==0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1019"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[predictions==1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "386"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[predictions==0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "GCN(\n  (conv1): GraphConv(in=3, out=4, normalization=both, activation=None)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (conv2): GraphConv(in=4, out=2, normalization=both, activation=None)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_model = GCN(3, num_classes=2)\n",
    "checkpoint_graph = 'output/graph_model.pt'\n",
    "graph_model.load_state_dict(torch.load(checkpoint_graph))\n",
    "graph_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "predictions = graph_model(g, g.ndata['feat']).argmax(1).numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "983"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(predictions[predictions==1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "422"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[predictions==0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}