{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from func.run_pipeline_super_vox import get_outlayer_of_a_3d_shape, get_crop_by_pixel_val\n",
    "from func.ultis import load_obj\n",
    "\n",
    "from func.graph_learning import SuperVoxToNxGraph, VoxelGraphDataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# load graphs\n",
    "from func.ultis import load_obj\n",
    "\n",
    "graphs = load_obj(\"graphs_dataset_train\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "dataset = VoxelGraphDataset(graphs)\n",
    "\n",
    "g = dataset[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO probably should normalize features!!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.696, accuracy: 0.488\n",
      "In epoch 20, loss: 0.693, accuracy: 0.513\n",
      "In epoch 40, loss: 0.693, accuracy: 0.516\n",
      "In epoch 60, loss: 0.692, accuracy: 0.544\n",
      "In epoch 80, loss: 0.692, accuracy: 0.596\n",
      "In epoch 100, loss: 0.692, accuracy: 0.608\n",
      "In epoch 120, loss: 0.692, accuracy: 0.607\n",
      "In epoch 140, loss: 0.692, accuracy: 0.662\n",
      "In epoch 160, loss: 0.692, accuracy: 0.663\n",
      "In epoch 180, loss: 0.692, accuracy: 0.658\n",
      "In epoch 200, loss: 0.692, accuracy: 0.670\n",
      "In epoch 220, loss: 0.691, accuracy: 0.692\n",
      "In epoch 240, loss: 0.691, accuracy: 0.669\n",
      "In epoch 260, loss: 0.691, accuracy: 0.705\n",
      "In epoch 280, loss: 0.691, accuracy: 0.707\n",
      "In epoch 300, loss: 0.692, accuracy: 0.684\n",
      "In epoch 320, loss: 0.691, accuracy: 0.682\n",
      "In epoch 340, loss: 0.691, accuracy: 0.711\n",
      "In epoch 360, loss: 0.692, accuracy: 0.669\n",
      "In epoch 380, loss: 0.691, accuracy: 0.714\n",
      "In epoch 400, loss: 0.692, accuracy: 0.684\n",
      "In epoch 420, loss: 0.691, accuracy: 0.707\n",
      "In epoch 440, loss: 0.692, accuracy: 0.712\n",
      "In epoch 460, loss: 0.692, accuracy: 0.698\n",
      "In epoch 480, loss: 0.691, accuracy: 0.687\n",
      "In epoch 500, loss: 0.691, accuracy: 0.701\n",
      "In epoch 520, loss: 0.691, accuracy: 0.703\n",
      "In epoch 540, loss: 0.691, accuracy: 0.702\n",
      "In epoch 560, loss: 0.691, accuracy: 0.729\n",
      "In epoch 580, loss: 0.691, accuracy: 0.712\n",
      "In epoch 600, loss: 0.691, accuracy: 0.683\n",
      "In epoch 620, loss: 0.691, accuracy: 0.708\n",
      "In epoch 640, loss: 0.691, accuracy: 0.706\n",
      "In epoch 660, loss: 0.692, accuracy: 0.712\n",
      "In epoch 680, loss: 0.691, accuracy: 0.729\n",
      "In epoch 700, loss: 0.692, accuracy: 0.714\n",
      "In epoch 720, loss: 0.691, accuracy: 0.715\n",
      "In epoch 740, loss: 0.692, accuracy: 0.721\n",
      "In epoch 760, loss: 0.691, accuracy: 0.706\n",
      "In epoch 780, loss: 0.692, accuracy: 0.713\n",
      "In epoch 800, loss: 0.691, accuracy: 0.721\n",
      "In epoch 820, loss: 0.691, accuracy: 0.700\n",
      "In epoch 840, loss: 0.692, accuracy: 0.719\n",
      "In epoch 860, loss: 0.691, accuracy: 0.717\n",
      "In epoch 880, loss: 0.691, accuracy: 0.711\n",
      "In epoch 900, loss: 0.691, accuracy: 0.719\n",
      "In epoch 920, loss: 0.692, accuracy: 0.702\n",
      "In epoch 940, loss: 0.691, accuracy: 0.715\n",
      "In epoch 960, loss: 0.691, accuracy: 0.715\n",
      "In epoch 980, loss: 0.691, accuracy: 0.713\n",
      "In epoch 1000, loss: 0.691, accuracy: 0.715\n",
      "In epoch 1020, loss: 0.691, accuracy: 0.719\n",
      "In epoch 1040, loss: 0.691, accuracy: 0.721\n",
      "In epoch 1060, loss: 0.691, accuracy: 0.719\n",
      "In epoch 1080, loss: 0.691, accuracy: 0.711\n",
      "In epoch 1100, loss: 0.691, accuracy: 0.717\n",
      "In epoch 1120, loss: 0.691, accuracy: 0.720\n",
      "In epoch 1140, loss: 0.692, accuracy: 0.710\n",
      "In epoch 1160, loss: 0.691, accuracy: 0.714\n",
      "In epoch 1180, loss: 0.691, accuracy: 0.723\n",
      "In epoch 1200, loss: 0.691, accuracy: 0.727\n",
      "In epoch 1220, loss: 0.691, accuracy: 0.711\n",
      "In epoch 1240, loss: 0.691, accuracy: 0.709\n",
      "In epoch 1260, loss: 0.691, accuracy: 0.731\n",
      "In epoch 1280, loss: 0.691, accuracy: 0.737\n",
      "In epoch 1300, loss: 0.691, accuracy: 0.728\n",
      "In epoch 1320, loss: 0.691, accuracy: 0.734\n",
      "In epoch 1340, loss: 0.691, accuracy: 0.734\n",
      "In epoch 1360, loss: 0.691, accuracy: 0.727\n",
      "In epoch 1380, loss: 0.691, accuracy: 0.722\n",
      "In epoch 1400, loss: 0.691, accuracy: 0.723\n",
      "In epoch 1420, loss: 0.691, accuracy: 0.726\n",
      "In epoch 1440, loss: 0.691, accuracy: 0.730\n",
      "In epoch 1460, loss: 0.691, accuracy: 0.716\n",
      "In epoch 1480, loss: 0.691, accuracy: 0.745\n",
      "In epoch 1500, loss: 0.691, accuracy: 0.718\n",
      "In epoch 1520, loss: 0.691, accuracy: 0.722\n",
      "In epoch 1540, loss: 0.691, accuracy: 0.713\n",
      "In epoch 1560, loss: 0.692, accuracy: 0.715\n",
      "In epoch 1580, loss: 0.691, accuracy: 0.723\n",
      "In epoch 1600, loss: 0.691, accuracy: 0.729\n",
      "In epoch 1620, loss: 0.691, accuracy: 0.735\n",
      "In epoch 1640, loss: 0.691, accuracy: 0.723\n",
      "In epoch 1660, loss: 0.691, accuracy: 0.735\n",
      "In epoch 1680, loss: 0.691, accuracy: 0.735\n",
      "In epoch 1700, loss: 0.691, accuracy: 0.740\n",
      "In epoch 1720, loss: 0.691, accuracy: 0.744\n",
      "In epoch 1740, loss: 0.691, accuracy: 0.740\n",
      "In epoch 1760, loss: 0.691, accuracy: 0.712\n",
      "In epoch 1780, loss: 0.691, accuracy: 0.740\n",
      "In epoch 1800, loss: 0.691, accuracy: 0.714\n",
      "In epoch 1820, loss: 0.691, accuracy: 0.715\n",
      "In epoch 1840, loss: 0.691, accuracy: 0.735\n",
      "In epoch 1860, loss: 0.691, accuracy: 0.743\n",
      "In epoch 1880, loss: 0.691, accuracy: 0.737\n",
      "In epoch 1900, loss: 0.691, accuracy: 0.741\n",
      "In epoch 1920, loss: 0.691, accuracy: 0.741\n",
      "In epoch 1940, loss: 0.691, accuracy: 0.743\n",
      "In epoch 1960, loss: 0.691, accuracy: 0.733\n",
      "In epoch 1980, loss: 0.691, accuracy: 0.738\n"
     ]
    }
   ],
   "source": [
    "from func.graph_models import GCN, GCN_2\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "model = GCN(1, num_classes=2)\n",
    "CELoss = nn.CrossEntropyLoss()\n",
    "\n",
    "# training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "best_val_acc = 0\n",
    "\n",
    "\n",
    "\n",
    "# features = g.ndata['feat']\n",
    "# labels = g.ndata['label']\n",
    "# train_mask = g.ndata['train_mask']\n",
    "# val_mask = g.ndata['val_mask']\n",
    "\n",
    "# calculate weights for loss\n",
    "\"\"\"\n",
    "pos_weights = []\n",
    "neg_weights = []\n",
    "for graph_number in range(len(dataset)):\n",
    "    sample_graph = dataset[graph_number]\n",
    "    labels = sample_graph.ndata['label']\n",
    "    # create class weights\n",
    "    number_positives = torch.count_nonzero(labels)\n",
    "    positive_weight = 1 - (number_positives / len(labels))\n",
    "    negative_weight = 1 - positive_weight\n",
    "\n",
    "    pos_weights.append(positive_weight.item())\n",
    "    neg_weights.append(negative_weight.item())\n",
    "weights = torch.tensor([mean(neg_weights), mean(pos_weights)])\n",
    "print(f\"weights: {weights}\")\n",
    "\"\"\"\n",
    "epoch_loss = []\n",
    "epoch_accuracy = []\n",
    "for e in range(2000):\n",
    "    # get random elements for batch\n",
    "    #graphs_numbers_list = range(0, len(dataset))\n",
    "    #rand_graph_numbers = random.sample(graphs_numbers_list, len(dataset))\n",
    "    for graph_number in range(len(dataset)):\n",
    "    #for graph_number in range(1):\n",
    "    #for graph_number in rand_graph_numbers:\n",
    "        # Forward\n",
    "        sample_graph = dataset[graph_number]\n",
    "        features = sample_graph.ndata['feat']\n",
    "        labels = sample_graph.ndata['label']\n",
    "\n",
    "        # create class weights\n",
    "        number_positives = torch.count_nonzero(labels)\n",
    "        percentage_positives = number_positives / len(labels)\n",
    "        percentage_negatives = 1 - percentage_positives\n",
    "\n",
    "        weights = torch.tensor([1 - percentage_negatives, 1 - percentage_positives])\n",
    "        #weights = torch.tensor([0.95, 0.05])\n",
    "        #print(weights)\n",
    "\n",
    "        CELoss = nn.CrossEntropyLoss(weight=weights)\n",
    "        #train_mask = sample_graph.ndata['train_mask']\n",
    "        #val_mask = sample_graph.ndata['val_mask']\n",
    "        logits = model(sample_graph, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = CELoss(logits, labels)\n",
    "        epoch_loss.append(loss.item())\n",
    "        #print(loss)\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred == labels).float().mean()\n",
    "        epoch_accuracy.append(train_acc.item())\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        print('In epoch {}, loss: {:.3f}, accuracy: {:.3f}'.format(\n",
    "            e, mean(epoch_loss), mean(epoch_accuracy)))\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on GPU\n",
    "g = g.to('cuda')\n",
    "model = GCN(1, 16, dataset.num_classes).to('cuda')\n",
    "train(g, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "g.ndata['feat'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "predictions = model(g, g.ndata['feat']).argmax(1).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = g.ndata['label']\n",
    "np.unique(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(labels[labels==1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(labels[labels==0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}