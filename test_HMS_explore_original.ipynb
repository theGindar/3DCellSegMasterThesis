{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import edt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from skimage.metrics import adapted_rand_error\n",
    "\n",
    "import torch\n",
    "from torch import from_numpy as from_numpy\n",
    "from torchsummary import summary\n",
    "\n",
    "from func.run_pipeline_super_vox import segment_super_vox_3_channel, semantic_segment_crop_and_cat_3_channel_output, img_3d_erosion_or_expansion, \\\n",
    "generate_super_vox_by_watershed, get_outlayer_of_a_3d_shape, get_crop_by_pixel_val, Cluster_Super_Vox, assign_boudary_voxels_to_cells_with_watershed, \\\n",
    "delete_too_small_cluster, reassign\n",
    "from func.run_pipeline import segment, assign_boudary_voxels_to_cells, dbscan_of_seg, semantic_segment_crop_and_cat\n",
    "from func.cal_accuracy import IOU_and_Dice_Accuracy, VOI\n",
    "from func.network import VoxResNet, CellSegNet_basic_lite_w_groupnorm, CellSegNet_basic_edge_gated_IV\n",
    "from func.unet_3d_basic import UNet3D_basic\n",
    "from func.ultis import save_obj, load_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nfor child in model.children():\\n    print(child)\\n    if type(child).__name__.startswith('BatchNorm'):\\n        child.track_running_stats = False\\n\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model=UNet3D_basic(in_channels = 1, out_channels = 3)\n",
    "# load_path=''\n",
    "# model=VoxResNet(input_channel=1, n_classes=3, output_func = \"softmax\")\n",
    "# load_path=\"\"\n",
    "model=CellSegNet_basic_lite_w_groupnorm(input_channel=1, n_classes=3, output_func = \"softmax\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "load_path='output/model_HMS_w_groupnorm_batchsize5.pkl'\n",
    "checkpoint = torch.load(load_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "\"\"\"\n",
    "for child in model.children():\n",
    "    print(child)\n",
    "    if type(child).__name__.startswith('BatchNorm'):\n",
    "        child.track_running_stats = False\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#summary(model, (1, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMS_data_dict = load_obj(\"dataset_info/HMS_dataset_info\")\n",
    "HMS_data_dict_test = HMS_data_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seg one img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not input the whole raw image to the model one time but input raw image crops\n",
    "crop_cube_size=64\n",
    "stride=32\n",
    "\n",
    "# hyperparameter for TASCAN, min touching area of two super pixels if they belong to the same cell\n",
    "min_touching_area=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose a test image and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases: dict_keys(['135', '120', '65', '90'])\n",
      "for test case 135 : {'raw': 'data/CellSeg_dataset/HMS_processed/raw/135.npy', 'background': 'data/CellSeg_dataset/HMS_processed/segmentation/135/135_background_3d_mask.npy', 'boundary': 'data/CellSeg_dataset/HMS_processed/segmentation/135/135_boundary_3d_mask.npy', 'foreground': 'data/CellSeg_dataset/HMS_processed/segmentation/135/135_foreground_3d_mask.npy', 'ins': 'data/CellSeg_dataset/HMS_processed/segmentation/135/135_ins.npy'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Test cases: \"+str(HMS_data_dict_test.keys()))\n",
    "case = \"135\"\n",
    "print(\"for test case \"+str(case)+\" : \"+str(HMS_data_dict_test[case]))\n",
    "\n",
    "# you may load the image using another path\n",
    "raw_img=np.load(HMS_data_dict_test[case][\"raw\"]).astype(float)\n",
    "hand_seg=np.load(HMS_data_dict_test[case][\"ins\"]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get gt boundary\n",
    "\n",
    "boundary_gt = np.load(HMS_data_dict_test[case][\"boundary\"]).astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feed raw image crops to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "start = time.time()\n",
    "\n",
    "# feed the raw img to the model\n",
    "print('Feed raw img to model')\n",
    "raw_img_size=raw_img.shape\n",
    "    \n",
    "seg_background_comp = np.zeros(raw_img_size)\n",
    "seg_boundary_comp = np.zeros(raw_img_size)\n",
    "\n",
    "transposes = [[0,1,2]]#,[2,0,1],[0,2,1]]\n",
    "reverse_transposes = [[0,1,2]]#,[1,2,0],[0,2,1]]\n",
    "\n",
    "for idx, transpose in enumerate(transposes):\n",
    "    print(str(idx+1)+\": Transpose the image to be: \"+str(transpose))\n",
    "    with torch.no_grad():\n",
    "        seg_img =\\\n",
    "        semantic_segment_crop_and_cat_3_channel_output(raw_img.transpose(transpose), model, device, crop_cube_size=crop_cube_size, stride=stride)\n",
    "    seg_img_background=seg_img['background']\n",
    "    seg_img_boundary=seg_img['boundary']\n",
    "    seg_img_foreground=seg_img['foreground']\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # argmax\n",
    "    print('argmax', end='\\r')\n",
    "    seg=[]\n",
    "    seg.append(seg_img_background)\n",
    "    seg.append(seg_img_boundary)\n",
    "    seg.append(seg_img_foreground)\n",
    "    seg=np.array(seg)\n",
    "    seg_argmax=np.argmax(seg, axis=0)\n",
    "    # probability map to 0 1 segment\n",
    "    seg_background=np.zeros(seg_img_background.shape)\n",
    "    seg_background[np.where(seg_argmax==0)]=1\n",
    "    seg_foreground=np.zeros(seg_img_foreground.shape)\n",
    "    seg_foreground[np.where(seg_argmax==2)]=1\n",
    "    seg_boundary=np.zeros(seg_img_boundary.shape)\n",
    "    seg_boundary[np.where(seg_argmax==1)]=1\n",
    "        \n",
    "    seg_background=seg_background.transpose(reverse_transposes[idx])\n",
    "    seg_foreground=seg_foreground.transpose(reverse_transposes[idx])\n",
    "    seg_boundary=seg_boundary.transpose(reverse_transposes[idx])\n",
    "        \n",
    "    seg_background_comp+=seg_background\n",
    "    seg_boundary_comp+=seg_boundary\n",
    "#print(\"Get model semantic seg by combination\")\n",
    "seg_background_comp = np.array(seg_background_comp>0, dtype=float)\n",
    "seg_boundary_comp = np.array(seg_boundary_comp>0, dtype=float)\n",
    "seg_foreground_comp = np.array(1 - seg_background_comp - seg_boundary_comp>0, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time elapsed: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# show current result\n",
    "\n",
    "N=100\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"raw_img\")\n",
    "plt.imshow(raw_img[:,:,N])\n",
    "plt.figure()\n",
    "plt.title(\"hand_seg\")\n",
    "plt.imshow(reassign(hand_seg[:,:,N]))\n",
    "plt.figure()\n",
    "plt.title(\"model_seg_foreground\")\n",
    "plt.imshow(seg_foreground_comp[:,:,N])\n",
    "plt.figure()\n",
    "plt.title(\"model_seg_boundary\")\n",
    "plt.imshow(seg_boundary_comp[:,:,N])\n",
    "plt.figure()\n",
    "plt.title(\"boundary ground truth\")\n",
    "plt.imshow(boundary_gt[:,:,N])\n",
    "plt.figure()\n",
    "plt.title(\"model_seg_background\")\n",
    "plt.imshow(seg_background_comp[:,:,N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate super vox by watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "how_close_are_the_super_vox_to_boundary=2\n",
    "min_touching_percentage=0.51\n",
    "\n",
    "seg_foreground_erosion=1-img_3d_erosion_or_expansion(1-seg_foreground_comp, kernel_size=how_close_are_the_super_vox_to_boundary+1, device=device)\n",
    "seg_foreground_super_voxel_by_ws = generate_super_vox_by_watershed(seg_foreground_erosion, connectivity=min_touching_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"seg foreground erosion\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_erosion[:,:,N])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"seg foreground\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_comp[:,:,N])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"1 - seg foreground\")\n",
    "plt.axis('off')\n",
    "plt.imshow(1-seg_foreground_comp[:,:,N])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "print(\"There are \"+str(len(np.unique(seg_foreground_super_voxel_by_ws)))+\" super voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "super voxel clustearing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "cluster_super_vox=Cluster_Super_Vox(min_touching_area=min_touching_area, min_touching_percentage=min_touching_percentage)\n",
    "cluster_super_vox.fit(seg_foreground_super_voxel_by_ws)\n",
    "seg_foreground_single_cell_with_boundary = cluster_super_vox.output_3d_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete too small cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "min_cell_size_threshold=10\n",
    "seg_foreground_single_cell_with_boundary_delete_too_small = delete_too_small_cluster(seg_foreground_single_cell_with_boundary, threshold=min_cell_size_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign boudary voxels to their nearest cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "seg_final=assign_boudary_voxels_to_cells_with_watershed(seg_foreground_single_cell_with_boundary_delete_too_small, seg_boundary_comp, seg_background_comp, compactness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorful_seg(seg):\n",
    "    unique_vals, val_counts = np.unique(seg, return_counts=True)\n",
    "    \n",
    "    background_val = unique_vals[np.argsort(val_counts)[::-1][0]]\n",
    "    \n",
    "    seg_RGB = []\n",
    "    for i in range(seg.shape[0]):\n",
    "        mask_gray = cv2.normalize(src=seg[i,:,:], dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        seg_slice_RGB = cv2.cvtColor(mask_gray, cv2.COLOR_GRAY2RGB)\n",
    "        seg_RGB.append(seg_slice_RGB)\n",
    "    seg_RGB = np.array(seg_RGB)\n",
    "    \n",
    "    for idx, unique_val in enumerate(unique_vals):\n",
    "        print(str(idx/len(unique_vals)), end=\"\\r\")\n",
    "        if unique_val == background_val:\n",
    "            COLOR = np.array([0,0,0], dtype=int)\n",
    "        else:\n",
    "            COLOR = np.array(np.random.choice(np.arange(256), size=3, replace=False), dtype=int)\n",
    "        \n",
    "        locs = np.where(seg==unique_val)\n",
    "        \n",
    "        for i in range(3):\n",
    "            seg_RGB[locs[0], locs[1], locs[2], i] = COLOR[i]\n",
    "        \n",
    "    return seg_RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "seg_RGB = colorful_seg(seg_final)\n",
    "hand_seg_RGB = colorful_seg(hand_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "N=100\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"supervoxels\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_super_voxel_by_ws[:,:,N])#, cmap=\"gray\")\n",
    "#plt.savefig('_RGB_'+str(N)+'.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "N=100\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"supervoxels after grouping\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_single_cell_with_boundary[:,:,N])#, cmap=\"gray\")\n",
    "#plt.savefig('_RGB_'+str(N)+'.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"seg foreground\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_comp[:,:,N])#, cmap=\"gray\")\n",
    "#plt.savefig('_RGB_'+str(N)+'.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "N=100\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"model seg\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_RGB[:,:,N,:])#, cmap=\"gray\")\n",
    "#plt.savefig('_RGB_'+str(N)+'.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"hand seg\")\n",
    "plt.axis('off')\n",
    "plt.imshow(hand_seg_RGB[:,:,N,:])#,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"There are \"+str(len(np.unique(seg_final)))+\" cells in model prediction\")\n",
    "# print(\"There are \"+str(len(np.unique(hand_seg)))+\" cells in hand seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ARI = adjusted_rand_score(hand_seg.flatten(), seg_final.flatten())\n",
    "ARE = adapted_rand_error(hand_seg.astype(int).flatten(), seg_final.astype(int).flatten())\n",
    "VOI_val = VOI(seg_final.astype(int),hand_seg.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "print(\"ARI: \"+str(ARI))\n",
    "print(\"ARE: \"+str(ARE))\n",
    "print(\"VOI: \"+str(VOI_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_3d_interpolate(img_3d, output_size, device = torch.device('cpu'), mode='nearest'):\n",
    "    img_3d = img_3d.reshape(1,1,img_3d.shape[0],img_3d.shape[1],img_3d.shape[2])\n",
    "    img_3d=torch.from_numpy(img_3d).float().to(device)\n",
    "    img_3d=torch.nn.functional.interpolate(img_3d, size=output_size, mode='nearest')\n",
    "    img_3d=img_3d.detach().cpu().numpy()\n",
    "    img_3d=img_3d.reshape(img_3d.shape[2],img_3d.shape[3],img_3d.shape[4])\n",
    "    \n",
    "    return img_3d\n",
    "\n",
    "scale_factor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "org_shape = seg_final.shape\n",
    "output_size = (int(org_shape[0]*scale_factor), int(org_shape[1]*scale_factor), int(org_shape[2]*scale_factor))\n",
    "print(str(org_shape)+\" --> \"+str(output_size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "accuracy=IOU_and_Dice_Accuracy(img_3d_interpolate(hand_seg, output_size = output_size), img_3d_interpolate(seg_final, output_size = output_size))\n",
    "accuracy_record=accuracy.cal_accuracy_II()\n",
    "\n",
    "iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
    "print('cell count accuracy iou >0.7: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
    "print('cell count accuracy dice >0.7: '+str(sum(dice)/len(dice)))\n",
    "    \n",
    "iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
    "print('cell count accuracy iou >0.5: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n",
    "print('cell count accuracy dice >0.5: '+str(sum(dice)/len(dice)))\n",
    "\n",
    "print('avg iou: '+str(np.mean(accuracy_record[:,1])))\n",
    "print('avg dice: '+str(np.mean(accuracy_record[:,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seg all imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_3d_interpolate(img_3d, output_size, device = torch.device('cpu'), mode='nearest'):\n",
    "    img_3d = img_3d.reshape(1,1,img_3d.shape[0],img_3d.shape[1],img_3d.shape[2])\n",
    "    img_3d=torch.from_numpy(img_3d).float().to(device)\n",
    "    img_3d=torch.nn.functional.interpolate(img_3d, size=output_size, mode='nearest')\n",
    "    img_3d=img_3d.detach().cpu().numpy()\n",
    "    img_3d=img_3d.reshape(img_3d.shape[2],img_3d.shape[3],img_3d.shape[4])\n",
    "    \n",
    "    return img_3d\n",
    "\n",
    "def pipeline(raw_img, hand_seg, model, device,\n",
    "             crop_cube_size, stride,\n",
    "             how_close_are_the_super_vox_to_boundary=2,\n",
    "             min_touching_area=30,\n",
    "             min_touching_percentage=0.51,\n",
    "             min_cell_size_threshold=1,\n",
    "             transposes = [[0,1,2]], reverse_transposes = [[0,1,2]],\n",
    "             test_file_name = None):\n",
    "    \n",
    "    seg_final=segment_super_vox_3_channel(raw_img, model, device,\n",
    "                                          crop_cube_size=crop_cube_size, stride=stride,\n",
    "                                          how_close_are_the_super_vox_to_boundary=how_close_are_the_super_vox_to_boundary,\n",
    "                                          min_touching_area=min_touching_area,\n",
    "                                          min_touching_percentage=min_touching_percentage,\n",
    "                                          min_cell_size_threshold=min_cell_size_threshold,\n",
    "                                          transposes = transposes, reverse_transposes = reverse_transposes,\n",
    "                                          test_file_name=test_file_name,\n",
    "                                          intermediate_results_save_path=\"../masterthesis_results/HMS_original_groupnorm/\")\n",
    "    \n",
    "    ari = adjusted_rand_score(hand_seg.flatten(), seg_final.flatten())\n",
    "    voi = VOI(seg_final.astype(np.int),hand_seg.astype(np.int))\n",
    "    \n",
    "    scale_factor = 0.5\n",
    "    org_shape = seg_final.shape\n",
    "    output_size = (int(org_shape[0]*scale_factor), int(org_shape[1]*scale_factor), int(org_shape[2]*scale_factor))\n",
    "    print(str(org_shape)+\" --> \"+str(output_size))\n",
    "    \n",
    "    accuracy=IOU_and_Dice_Accuracy(img_3d_interpolate(hand_seg, output_size = output_size),\n",
    "                                   img_3d_interpolate(seg_final, output_size = output_size))\n",
    "    accuracy_record=accuracy.cal_accuracy_II()\n",
    "    hand_seg_after_accuracy=accuracy.gt\n",
    "    seg_final_after_accuracy=accuracy.pred\n",
    "    \n",
    "    return accuracy_record, hand_seg_after_accuracy, seg_final_after_accuracy, ari, voi, seg_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "Feed raw img to model. Use different transposes\n",
      "1: Transpose the image to be: [0, 1, 2]\n",
      "argmax\rs of segment_3d_img: 99%Get model semantic seg by combination\n",
      "number of valid_neighbor_vals: 0\r886666 and 2e-08077current_crop_outlayer_area: 21current_crop_outlayer_area: 6current_crop_outlayer_area: 137current_crop_outlayer_area: 16current_crop_outlayer_area: 99current_crop_outlayer_area: 20current_crop_outlayer_area: 14current_crop_outlayer_area: 26current_crop_outlayer_area: 16current_crop_outlayer_area: 23current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 101current_crop_outlayer_area: 15current_crop_outlayer_area: 59current_crop_outlayer_area: 0current_crop_outlayer_area: 27current_crop_outlayer_area: 36current_crop_outlayer_area: 62current_crop_outlayer_area: 14current_crop_outlayer_area: 123current_crop_outlayer_area: 0current_crop_outlayer_area: 7current_crop_outlayer_area: 2current_crop_outlayer_area: 31current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 15current_crop_outlayer_area: 50current_crop_outlayer_area: 44current_crop_outlayer_area: 27current_crop_outlayer_area: 21current_crop_outlayer_area: 29current_crop_outlayer_area: 7current_crop_outlayer_area: 66current_crop_outlayer_area: 13current_crop_outlayer_area: 22current_crop_outlayer_area: 2current_crop_outlayer_area: 27current_crop_outlayer_area: 17current_crop_outlayer_area: 20current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 5current_crop_outlayer_area: 0current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 8current_crop_outlayer_area: 3current_crop_outlayer_area: 72current_crop_outlayer_area: 0current_crop_outlayer_area: 29current_crop_outlayer_area: 11current_crop_outlayer_area: 52current_crop_outlayer_area: 29current_crop_outlayer_area: 27current_crop_outlayer_area: 23current_crop_outlayer_area: 6current_crop_outlayer_area: 11current_crop_outlayer_area: 9current_crop_outlayer_area: 35current_crop_outlayer_area: 26current_crop_outlayer_area: 0current_crop_outlayer_area: 28current_crop_outlayer_area: 20current_crop_outlayer_area: 10current_crop_outlayer_area: 41current_crop_outlayer_area: 0current_crop_outlayer_area: 70current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 8current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 21current_crop_outlayer_area: 29current_crop_outlayer_area: 34current_crop_outlayer_area: 4current_crop_outlayer_area: 13current_crop_outlayer_area: 18current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 3current_crop_outlayer_area: 3current_crop_outlayer_area: 23current_crop_outlayer_area: 42current_crop_outlayer_area: 5current_crop_outlayer_area: 18current_crop_outlayer_area: 12current_crop_outlayer_area: 1current_crop_outlayer_area: 37current_crop_outlayer_area: 13current_crop_outlayer_area: 0current_crop_outlayer_area: 63current_crop_outlayer_area: 6current_crop_outlayer_area: 10current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 20current_crop_outlayer_area: 38current_crop_outlayer_area: 12current_crop_outlayer_area: 105current_crop_outlayer_area: 48current_crop_outlayer_area: 21current_crop_outlayer_area: 25current_crop_outlayer_area: 0current_crop_outlayer_area: 28current_crop_outlayer_area: 48current_crop_outlayer_area: 19current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 27current_crop_outlayer_area: 15current_crop_outlayer_area: 52current_crop_outlayer_area: 79current_crop_outlayer_area: 40current_crop_outlayer_area: 36current_crop_outlayer_area: 4current_crop_outlayer_area: 13current_crop_outlayer_area: 28current_crop_outlayer_area: 23current_crop_outlayer_area: 0current_crop_outlayer_area: 37current_crop_outlayer_area: 20current_crop_outlayer_area: 45current_crop_outlayer_area: 0current_crop_outlayer_area: 46current_crop_outlayer_area: 36current_crop_outlayer_area: 0current_crop_outlayer_area: 23current_crop_outlayer_area: 17current_crop_outlayer_area: 4current_crop_outlayer_area: 1current_crop_outlayer_area: 37current_crop_outlayer_area: 17current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 68current_crop_outlayer_area: 24current_crop_outlayer_area: 40current_crop_outlayer_area: 35current_crop_outlayer_area: 3current_crop_outlayer_area: 2current_crop_outlayer_area: 38current_crop_outlayer_area: 12current_crop_outlayer_area: 15current_crop_outlayer_area: 21current_crop_outlayer_area: 31current_crop_outlayer_area: 2current_crop_outlayer_area: 16current_crop_outlayer_area: 0current_crop_outlayer_area: 36current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 7current_crop_outlayer_area: 22current_crop_outlayer_area: 7current_crop_outlayer_area: 94current_crop_outlayer_area: 4current_crop_outlayer_area: 13current_crop_outlayer_area: 27current_crop_outlayer_area: 22current_crop_outlayer_area: 40current_crop_outlayer_area: 3current_crop_outlayer_area: 7current_crop_outlayer_area: 51current_crop_outlayer_area: 6current_crop_outlayer_area: 45current_crop_outlayer_area: 43current_crop_outlayer_area: 41current_crop_outlayer_area: 9current_crop_outlayer_area: 42current_crop_outlayer_area: 26current_crop_outlayer_area: 5current_crop_outlayer_area: 43current_crop_outlayer_area: 68current_crop_outlayer_area: 21current_crop_outlayer_area: 0current_crop_outlayer_area: 39current_crop_outlayer_area: 0current_crop_outlayer_area: 37current_crop_outlayer_area: 20current_crop_outlayer_area: 7current_crop_outlayer_area: 8current_crop_outlayer_area: 42current_crop_outlayer_area: 7current_crop_outlayer_area: 35current_crop_outlayer_area: 6current_crop_outlayer_area: 30current_crop_outlayer_area: 20current_crop_outlayer_area: 6current_crop_outlayer_area: 19current_crop_outlayer_area: 22current_crop_outlayer_area: 36current_crop_outlayer_area: 30current_crop_outlayer_area: 17current_crop_outlayer_area: 39current_crop_outlayer_area: 12current_crop_outlayer_area: 35current_crop_outlayer_area: 17current_crop_outlayer_area: 10current_crop_outlayer_area: 60current_crop_outlayer_area: 2current_crop_outlayer_area: 4current_crop_outlayer_area: 3current_crop_outlayer_area: 1current_crop_outlayer_area: 6current_crop_outlayer_area: 22current_crop_outlayer_area: 15current_crop_outlayer_area: 9current_crop_outlayer_area: 2current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 7current_crop_outlayer_area: 5current_crop_outlayer_area: 9current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 4current_crop_outlayer_area: 1current_crop_outlayer_area: 5current_crop_outlayer_area: 6current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 1current_crop_outlayer_area: 4current_crop_outlayer_area: 4current_crop_outlayer_area: 1current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/2314792975.py:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  voi = VOI(seg_final.astype(np.int),hand_seg.astype(np.int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 331, 160) --> (90, 165, 80)\n",
      "progress: 99.7340425531915%\r\r\rrogress: 9.042553191489363%progress: 9.840425531914894%progress: 10.638297872340425%progress: 11.436170212765957%progress: 12.23404255319149%progress: 13.031914893617023%progress: 13.829787234042554%progress: 14.361702127659576%progress: 14.893617021276595%progress: 15.425531914893616%progress: 15.957446808510639%progress: 16.48936170212766%progress: 17.287234042553195%progress: 18.617021276595743%progress: 20.212765957446805%progress: 20.74468085106383%progress: 21.27659574468085%progress: 21.808510638297875%progress: 22.606382978723406%progress: 23.670212765957448%progress: 24.73404255319149%progress: 26.063829787234045%progress: 27.127659574468083%progress: 27.659574468085108%progress: 28.98936170212766%progress: 30.0531914893617%progress: 31.382978723404253%progress: 32.71276595744681%progress: 33.77659574468085%progress: 35.1063829787234%progress: 36.43617021276596%progress: 37.5%progress: 38.297872340425535%progress: 39.361702127659576%progress: 40.159574468085104%progress: 40.95744680851064%progress: 41.755319148936174%progress: 42.5531914893617%progress: 43.61702127659575%progress: 44.41489361702128%progress: 45.47872340425532%progress: 46.808510638297875%progress: 47.6063829787234%progress: 48.67021276595745%progress: 49.734042553191486%progress: 50.53191489361703%progress: 51.329787234042556%progress: 52.12765957446809%progress: 53.72340425531915%progress: 54.78723404255319%progress: 55.58510638297872%progress: 56.11702127659575%progress: 57.180851063829785%progress: 58.24468085106383%progress: 59.308510638297875%progress: 60.37234042553191%progress: 61.170212765957444%progress: 61.702127659574465%progress: 62.5%progress: 63.297872340425535%progress: 63.829787234042556%progress: 64.62765957446808%progress: 65.42553191489363%progress: 66.48936170212765%progress: 67.81914893617021%progress: 68.35106382978722%progress: 69.41489361702128%progress: 70.2127659574468%progress: 71.01063829787235%progress: 72.07446808510637%progress: 73.67021276595744%progress: 74.7340425531915%progress: 75.2659574468085%progress: 75.79787234042553%progress: 76.59574468085107%progress: 77.6595744680851%progress: 78.45744680851064%progress: 80.0531914893617%progress: 80.58510638297872%progress: 81.38297872340425%progress: 82.18085106382979%progress: 82.97872340425532%progress: 84.04255319148936%progress: 85.1063829787234%progress: 85.90425531914893%progress: 86.70212765957447%progress: 87.5%progress: 88.82978723404256%progress: 89.36170212765957%progress: 90.1595744680851%progress: 90.69148936170212%progress: 91.48936170212765%progress: 92.2872340425532%progress: 93.08510638297872%progress: 93.88297872340425%progress: 94.9468085106383%progress: 95.47872340425532%progress: 96.54255319148936%progress: 97.07446808510637%progress: 97.87234042553192%progress: 98.67021276595744%progress: 99.46808510638297%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell count accuracy iou >0.7: 0.3776595744680851\n",
      "cell count accuracy dice >0.7: 0.5558510638297872\n",
      "cell count accuracy iou >0.5: 0.598404255319149\n",
      "cell count accuracy dice >0.5: 0.75\n",
      "avg iou: 0.5204518265388114\n",
      "avg dice: 0.6381698403943409\n",
      "ari: 0.9887813120768859\n",
      "voi: (1.2387309735901193, 1.1821521195960722)\n",
      "----------\n",
      "120\n",
      "Feed raw img to model. Use different transposes\n",
      "1: Transpose the image to be: [0, 1, 2]\n",
      "argmax\rs of segment_3d_img: 99%Get model semantic seg by combination\n",
      "number of valid_neighbor_vals: 0\r885714 and 4e-080776current_crop_outlayer_area: 117current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 16current_crop_outlayer_area: 16current_crop_outlayer_area: 39current_crop_outlayer_area: 5current_crop_outlayer_area: 0current_crop_outlayer_area: 6current_crop_outlayer_area: 2current_crop_outlayer_area: 35current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 6current_crop_outlayer_area: 0current_crop_outlayer_area: 5current_crop_outlayer_area: 11current_crop_outlayer_area: 29current_crop_outlayer_area: 6current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 19current_crop_outlayer_area: 5current_crop_outlayer_area: 1current_crop_outlayer_area: 20current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 18current_crop_outlayer_area: 2current_crop_outlayer_area: 46current_crop_outlayer_area: 8current_crop_outlayer_area: 0current_crop_outlayer_area: 50current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 121current_crop_outlayer_area: 5current_crop_outlayer_area: 8current_crop_outlayer_area: 19current_crop_outlayer_area: 0current_crop_outlayer_area: 60current_crop_outlayer_area: 14current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 32current_crop_outlayer_area: 13current_crop_outlayer_area: 5current_crop_outlayer_area: 57current_crop_outlayer_area: 0current_crop_outlayer_area: 10current_crop_outlayer_area: 126current_crop_outlayer_area: 22current_crop_outlayer_area: 21current_crop_outlayer_area: 69current_crop_outlayer_area: 0current_crop_outlayer_area: 20current_crop_outlayer_area: 4current_crop_outlayer_area: 55current_crop_outlayer_area: 105current_crop_outlayer_area: 0current_crop_outlayer_area: 8current_crop_outlayer_area: 31current_crop_outlayer_area: 23current_crop_outlayer_area: 53current_crop_outlayer_area: 0current_crop_outlayer_area: 94current_crop_outlayer_area: 33current_crop_outlayer_area: 28current_crop_outlayer_area: 8current_crop_outlayer_area: 7current_crop_outlayer_area: 17current_crop_outlayer_area: 7current_crop_outlayer_area: 42current_crop_outlayer_area: 54current_crop_outlayer_area: 22current_crop_outlayer_area: 98current_crop_outlayer_area: 0current_crop_outlayer_area: 22current_crop_outlayer_area: 2current_crop_outlayer_area: 29current_crop_outlayer_area: 10current_crop_outlayer_area: 0current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 40current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 93current_crop_outlayer_area: 24current_crop_outlayer_area: 18current_crop_outlayer_area: 8current_crop_outlayer_area: 3current_crop_outlayer_area: 31current_crop_outlayer_area: 28current_crop_outlayer_area: 6current_crop_outlayer_area: 37current_crop_outlayer_area: 0current_crop_outlayer_area: 25current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 2current_crop_outlayer_area: 46current_crop_outlayer_area: 10current_crop_outlayer_area: 61current_crop_outlayer_area: 4current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 38current_crop_outlayer_area: 61current_crop_outlayer_area: 2current_crop_outlayer_area: 10current_crop_outlayer_area: 56current_crop_outlayer_area: 14current_crop_outlayer_area: 13current_crop_outlayer_area: 37current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 5current_crop_outlayer_area: 24current_crop_outlayer_area: 22current_crop_outlayer_area: 2current_crop_outlayer_area: 13current_crop_outlayer_area: 35current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 83current_crop_outlayer_area: 0current_crop_outlayer_area: 4current_crop_outlayer_area: 52current_crop_outlayer_area: 52current_crop_outlayer_area: 38current_crop_outlayer_area: 9current_crop_outlayer_area: 4current_crop_outlayer_area: 63current_crop_outlayer_area: 16current_crop_outlayer_area: 17current_crop_outlayer_area: 2current_crop_outlayer_area: 15current_crop_outlayer_area: 35current_crop_outlayer_area: 9current_crop_outlayer_area: 11current_crop_outlayer_area: 34current_crop_outlayer_area: 6current_crop_outlayer_area: 35current_crop_outlayer_area: 11current_crop_outlayer_area: 53current_crop_outlayer_area: 2current_crop_outlayer_area: 6current_crop_outlayer_area: 37current_crop_outlayer_area: 8current_crop_outlayer_area: 35current_crop_outlayer_area: 55current_crop_outlayer_area: 34current_crop_outlayer_area: 5current_crop_outlayer_area: 16current_crop_outlayer_area: 7current_crop_outlayer_area: 29current_crop_outlayer_area: 0current_crop_outlayer_area: 35current_crop_outlayer_area: 0current_crop_outlayer_area: 11current_crop_outlayer_area: 18current_crop_outlayer_area: 14current_crop_outlayer_area: 39current_crop_outlayer_area: 1current_crop_outlayer_area: 25current_crop_outlayer_area: 31current_crop_outlayer_area: 45current_crop_outlayer_area: 50current_crop_outlayer_area: 50current_crop_outlayer_area: 0current_crop_outlayer_area: 10current_crop_outlayer_area: 21current_crop_outlayer_area: 6current_crop_outlayer_area: 5current_crop_outlayer_area: 32current_crop_outlayer_area: 17current_crop_outlayer_area: 7current_crop_outlayer_area: 20current_crop_outlayer_area: 42current_crop_outlayer_area: 10current_crop_outlayer_area: 0current_crop_outlayer_area: 5current_crop_outlayer_area: 16current_crop_outlayer_area: 19current_crop_outlayer_area: 24current_crop_outlayer_area: 8current_crop_outlayer_area: 17current_crop_outlayer_area: 13current_crop_outlayer_area: 12current_crop_outlayer_area: 5current_crop_outlayer_area: 5current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 3current_crop_outlayer_area: 9current_crop_outlayer_area: 6current_crop_outlayer_area: 5current_crop_outlayer_area: 4current_crop_outlayer_area: 5current_crop_outlayer_area: 3current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 7current_crop_outlayer_area: 0current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/2314792975.py:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  voi = VOI(seg_final.astype(np.int),hand_seg.astype(np.int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 331, 160) --> (90, 165, 80)\n",
      "progress: 99.71910112359551%\r\rrogress: 4.775280898876404%progress: 5.8988764044943816%progress: 6.460674157303371%progress: 7.584269662921349%progress: 8.707865168539326%progress: 9.831460674157304%progress: 10.955056179775282%progress: 11.797752808988763%progress: 12.921348314606742%progress: 14.606741573033707%progress: 15.730337078651685%progress: 16.853932584269664%progress: 17.696629213483146%progress: 18.53932584269663%progress: 19.9438202247191%progress: 20.786516853932586%progress: 21.629213483146067%progress: 22.191011235955056%progress: 23.03370786516854%progress: 24.15730337078652%progress: 24.719101123595504%progress: 25.280898876404496%progress: 26.12359550561798%progress: 26.685393258426966%progress: 27.52808988764045%progress: 28.08988764044944%progress: 28.651685393258425%progress: 29.213483146067414%progress: 29.775280898876407%progress: 30.337078651685395%progress: 31.179775280898873%progress: 31.741573033707866%progress: 32.58426966292135%progress: 33.42696629213483%progress: 33.98876404494382%progress: 34.55056179775281%progress: 35.674157303370784%progress: 36.235955056179776%progress: 36.79775280898877%progress: 37.640449438202246%progress: 38.20224719101123%progress: 38.764044943820224%progress: 39.325842696629216%progress: 41.01123595505618%progress: 41.853932584269664%progress: 43.258426966292134%progress: 44.9438202247191%progress: 46.62921348314607%progress: 48.31460674157304%progress: 49.43820224719101%progress: 51.12359550561798%progress: 52.52808988764045%progress: 53.65168539325843%progress: 55.0561797752809%progress: 56.17977528089888%progress: 57.30337078651685%progress: 57.865168539325836%progress: 58.98876404494382%progress: 59.8314606741573%progress: 60.95505617977528%progress: 62.07865168539326%progress: 63.20224719101124%progress: 64.32584269662921%progress: 65.1685393258427%progress: 66.29213483146067%progress: 67.69662921348315%progress: 68.53932584269663%progress: 69.9438202247191%progress: 71.06741573033707%progress: 71.91011235955057%progress: 73.03370786516854%progress: 74.15730337078652%progress: 75.0%progress: 75.84269662921348%progress: 76.96629213483146%progress: 77.80898876404494%progress: 78.37078651685393%progress: 79.21348314606742%progress: 80.33707865168539%progress: 81.46067415730337%progress: 82.02247191011236%progress: 82.58426966292134%progress: 83.70786516853933%progress: 85.1123595505618%progress: 86.23595505617978%progress: 87.07865168539325%progress: 87.92134831460675%progress: 88.76404494382022%progress: 89.8876404494382%progress: 90.73033707865169%progress: 91.57303370786516%progress: 92.69662921348315%progress: 93.53932584269663%progress: 94.10112359550563%progress: 95.2247191011236%progress: 96.34831460674157%progress: 97.75280898876404%progress: 99.15730337078652%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell count accuracy iou >0.7: 0.4410112359550562\n",
      "cell count accuracy dice >0.7: 0.6207865168539326\n",
      "cell count accuracy iou >0.5: 0.651685393258427\n",
      "cell count accuracy dice >0.5: 0.8061797752808989\n",
      "avg iou: 0.5608052647197777\n",
      "avg dice: 0.6762947715829346\n",
      "ari: 0.9903133216110687\n",
      "voi: (1.1912324053886543, 1.1117598943602993)\n",
      "----------\n",
      "65\n",
      "Feed raw img to model. Use different transposes\n",
      "1: Transpose the image to be: [0, 1, 2]\n",
      "argmax\rs of segment_3d_img: 99%Get model semantic seg by combination\n",
      "number of valid_neighbor_vals: 0\r875675 and 2.1e-0776urrent_crop_outlayer_area: 121current_crop_outlayer_area: 99current_crop_outlayer_area: 21current_crop_outlayer_area: 135current_crop_outlayer_area: 21current_crop_outlayer_area: 116current_crop_outlayer_area: 31current_crop_outlayer_area: 8current_crop_outlayer_area: 55current_crop_outlayer_area: 8current_crop_outlayer_area: 88current_crop_outlayer_area: 89current_crop_outlayer_area: 133current_crop_outlayer_area: 95current_crop_outlayer_area: 111current_crop_outlayer_area: 14current_crop_outlayer_area: 192current_crop_outlayer_area: 68current_crop_outlayer_area: 16current_crop_outlayer_area: 17current_crop_outlayer_area: 95current_crop_outlayer_area: 194current_crop_outlayer_area: 0current_crop_outlayer_area: 93current_crop_outlayer_area: 31current_crop_outlayer_area: 2current_crop_outlayer_area: 11current_crop_outlayer_area: 5current_crop_outlayer_area: 20current_crop_outlayer_area: 22current_crop_outlayer_area: 32current_crop_outlayer_area: 6current_crop_outlayer_area: 22current_crop_outlayer_area: 39current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 11current_crop_outlayer_area: 8current_crop_outlayer_area: 5current_crop_outlayer_area: 22current_crop_outlayer_area: 46current_crop_outlayer_area: 26current_crop_outlayer_area: 9current_crop_outlayer_area: 44current_crop_outlayer_area: 9current_crop_outlayer_area: 90current_crop_outlayer_area: 29current_crop_outlayer_area: 15current_crop_outlayer_area: 4current_crop_outlayer_area: 8current_crop_outlayer_area: 49current_crop_outlayer_area: 93current_crop_outlayer_area: 31current_crop_outlayer_area: 87current_crop_outlayer_area: 20current_crop_outlayer_area: 158current_crop_outlayer_area: 41current_crop_outlayer_area: 23current_crop_outlayer_area: 30current_crop_outlayer_area: 115current_crop_outlayer_area: 97current_crop_outlayer_area: 10current_crop_outlayer_area: 81current_crop_outlayer_area: 88current_crop_outlayer_area: 5current_crop_outlayer_area: 13current_crop_outlayer_area: 43current_crop_outlayer_area: 1current_crop_outlayer_area: 27current_crop_outlayer_area: 12current_crop_outlayer_area: 41current_crop_outlayer_area: 21current_crop_outlayer_area: 94current_crop_outlayer_area: 0current_crop_outlayer_area: 92current_crop_outlayer_area: 13current_crop_outlayer_area: 57current_crop_outlayer_area: 68current_crop_outlayer_area: 33current_crop_outlayer_area: 56current_crop_outlayer_area: 41current_crop_outlayer_area: 79current_crop_outlayer_area: 0current_crop_outlayer_area: 40current_crop_outlayer_area: 75current_crop_outlayer_area: 87current_crop_outlayer_area: 0current_crop_outlayer_area: 14current_crop_outlayer_area: 25current_crop_outlayer_area: 61current_crop_outlayer_area: 59current_crop_outlayer_area: 0current_crop_outlayer_area: 7current_crop_outlayer_area: 11current_crop_outlayer_area: 71current_crop_outlayer_area: 8current_crop_outlayer_area: 38current_crop_outlayer_area: 54current_crop_outlayer_area: 14current_crop_outlayer_area: 24current_crop_outlayer_area: 0current_crop_outlayer_area: 67current_crop_outlayer_area: 31current_crop_outlayer_area: 106current_crop_outlayer_area: 51current_crop_outlayer_area: 35current_crop_outlayer_area: 3current_crop_outlayer_area: 63current_crop_outlayer_area: 23current_crop_outlayer_area: 40current_crop_outlayer_area: 51current_crop_outlayer_area: 54current_crop_outlayer_area: 31current_crop_outlayer_area: 2current_crop_outlayer_area: 5current_crop_outlayer_area: 55current_crop_outlayer_area: 51current_crop_outlayer_area: 0current_crop_outlayer_area: 38current_crop_outlayer_area: 30current_crop_outlayer_area: 20current_crop_outlayer_area: 16current_crop_outlayer_area: 23current_crop_outlayer_area: 26current_crop_outlayer_area: 19current_crop_outlayer_area: 28current_crop_outlayer_area: 58current_crop_outlayer_area: 43current_crop_outlayer_area: 42current_crop_outlayer_area: 53current_crop_outlayer_area: 11current_crop_outlayer_area: 36current_crop_outlayer_area: 24current_crop_outlayer_area: 10current_crop_outlayer_area: 1current_crop_outlayer_area: 23current_crop_outlayer_area: 8current_crop_outlayer_area: 24current_crop_outlayer_area: 15current_crop_outlayer_area: 3current_crop_outlayer_area: 22current_crop_outlayer_area: 23current_crop_outlayer_area: 8current_crop_outlayer_area: 3current_crop_outlayer_area: 5current_crop_outlayer_area: 12current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 13current_crop_outlayer_area: 7current_crop_outlayer_area: 13current_crop_outlayer_area: 7current_crop_outlayer_area: 6current_crop_outlayer_area: 1current_crop_outlayer_area: 9current_crop_outlayer_area: 4current_crop_outlayer_area: 1current_crop_outlayer_area: 2current_crop_outlayer_area: 9current_crop_outlayer_area: 4current_crop_outlayer_area: 26current_crop_outlayer_area: 1current_crop_outlayer_area: 5current_crop_outlayer_area: 2current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 4current_crop_outlayer_area: 1current_crop_outlayer_area: 3current_crop_outlayer_area: 1current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 1current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/2314792975.py:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  voi = VOI(seg_final.astype(np.int),hand_seg.astype(np.int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 331, 160) --> (90, 165, 80)\n",
      "progress: 99.67105263157895%\r\rogress: 6.578947368421052%progress: 8.223684210526317%progress: 9.868421052631579%progress: 10.855263157894738%progress: 12.5%progress: 14.144736842105262%progress: 15.460526315789474%progress: 16.776315789473685%progress: 19.078947368421055%progress: 20.723684210526315%progress: 21.710526315789476%progress: 22.697368421052634%progress: 23.684210526315788%progress: 24.671052631578945%progress: 25.32894736842105%progress: 26.31578947368421%progress: 26.973684210526315%progress: 27.960526315789476%progress: 28.947368421052634%progress: 29.605263157894733%progress: 30.592105263157894%progress: 31.25%progress: 32.56578947368421%progress: 33.55263157894737%progress: 34.21052631578947%progress: 35.19736842105263%progress: 35.85526315789473%progress: 36.84210526315789%progress: 37.5%progress: 38.48684210526316%progress: 39.473684210526315%progress: 40.78947368421053%progress: 41.776315789473685%progress: 42.43421052631579%progress: 43.42105263157895%progress: 44.73684210526316%progress: 45.723684210526315%progress: 46.381578947368425%progress: 47.03947368421053%progress: 47.69736842105263%progress: 49.01315789473684%progress: 49.67105263157895%progress: 50.6578947368421%progress: 51.64473684210527%progress: 52.63157894736842%progress: 53.61842105263158%progress: 54.60526315789473%progress: 55.92105263157895%progress: 57.23684210526315%progress: 57.89473684210527%progress: 59.539473684210535%progress: 61.18421052631579%progress: 61.8421052631579%progress: 62.82894736842105%progress: 64.14473684210526%progress: 64.80263157894737%progress: 66.11842105263158%progress: 67.43421052631578%progress: 68.42105263157895%progress: 69.4078947368421%progress: 70.39473684210526%progress: 71.71052631578947%progress: 72.69736842105263%progress: 74.01315789473685%progress: 75.0%progress: 76.31578947368422%progress: 77.30263157894737%progress: 78.61842105263158%progress: 79.60526315789474%progress: 81.57894736842105%progress: 82.23684210526315%progress: 83.22368421052632%progress: 84.21052631578947%progress: 85.19736842105263%progress: 86.18421052631578%progress: 86.8421052631579%progress: 88.48684210526315%progress: 89.80263157894737%progress: 90.78947368421053%progress: 91.44736842105263%progress: 93.0921052631579%progress: 94.4078947368421%progress: 95.72368421052632%progress: 96.38157894736842%progress: 97.36842105263158%progress: 98.35526315789474%progress: 99.3421052631579%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell count accuracy iou >0.7: 0.27960526315789475\n",
      "cell count accuracy dice >0.7: 0.42105263157894735\n",
      "cell count accuracy iou >0.5: 0.46710526315789475\n",
      "cell count accuracy dice >0.5: 0.6710526315789473\n",
      "avg iou: 0.4862710802262882\n",
      "avg dice: 0.6148497683860018\n",
      "ari: 0.9909201284033261\n",
      "voi: (1.2584500794969642, 1.3278350462874742)\n",
      "----------\n",
      "90\n",
      "Feed raw img to model. Use different transposes\n",
      "1: Transpose the image to be: [0, 1, 2]\n",
      "argmax\rs of segment_3d_img: 99%Get model semantic seg by combination\n",
      "number of valid_neighbor_vals: 0\r8641024 and 3.2e-076current_crop_outlayer_area: 2current_crop_outlayer_area: 22current_crop_outlayer_area: 52current_crop_outlayer_area: 45current_crop_outlayer_area: 107current_crop_outlayer_area: 6current_crop_outlayer_area: 8current_crop_outlayer_area: 13current_crop_outlayer_area: 58current_crop_outlayer_area: 11current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 7current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 88current_crop_outlayer_area: 117current_crop_outlayer_area: 6current_crop_outlayer_area: 65current_crop_outlayer_area: 111current_crop_outlayer_area: 45current_crop_outlayer_area: 13current_crop_outlayer_area: 10current_crop_outlayer_area: 2current_crop_outlayer_area: 1current_crop_outlayer_area: 72current_crop_outlayer_area: 25current_crop_outlayer_area: 24current_crop_outlayer_area: 19current_crop_outlayer_area: 0current_crop_outlayer_area: 128current_crop_outlayer_area: 13current_crop_outlayer_area: 40current_crop_outlayer_area: 79current_crop_outlayer_area: 0current_crop_outlayer_area: 49current_crop_outlayer_area: 11current_crop_outlayer_area: 53current_crop_outlayer_area: 40current_crop_outlayer_area: 24current_crop_outlayer_area: 42current_crop_outlayer_area: 6current_crop_outlayer_area: 9current_crop_outlayer_area: 0current_crop_outlayer_area: 4current_crop_outlayer_area: 0current_crop_outlayer_area: 8current_crop_outlayer_area: 3current_crop_outlayer_area: 8current_crop_outlayer_area: 66current_crop_outlayer_area: 77current_crop_outlayer_area: 11current_crop_outlayer_area: 48current_crop_outlayer_area: 64current_crop_outlayer_area: 110current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 32current_crop_outlayer_area: 59current_crop_outlayer_area: 9current_crop_outlayer_area: 30current_crop_outlayer_area: 81current_crop_outlayer_area: 41current_crop_outlayer_area: 0current_crop_outlayer_area: 41current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 8current_crop_outlayer_area: 23current_crop_outlayer_area: 38current_crop_outlayer_area: 92current_crop_outlayer_area: 49current_crop_outlayer_area: 52current_crop_outlayer_area: 5current_crop_outlayer_area: 82current_crop_outlayer_area: 29current_crop_outlayer_area: 60current_crop_outlayer_area: 53current_crop_outlayer_area: 57current_crop_outlayer_area: 35current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 12current_crop_outlayer_area: 23current_crop_outlayer_area: 0current_crop_outlayer_area: 92current_crop_outlayer_area: 0current_crop_outlayer_area: 27current_crop_outlayer_area: 1current_crop_outlayer_area: 37current_crop_outlayer_area: 7current_crop_outlayer_area: 79current_crop_outlayer_area: 3current_crop_outlayer_area: 13current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 9current_crop_outlayer_area: 42current_crop_outlayer_area: 76current_crop_outlayer_area: 39current_crop_outlayer_area: 0current_crop_outlayer_area: 67current_crop_outlayer_area: 74current_crop_outlayer_area: 41current_crop_outlayer_area: 9current_crop_outlayer_area: 4current_crop_outlayer_area: 36current_crop_outlayer_area: 63current_crop_outlayer_area: 2current_crop_outlayer_area: 33current_crop_outlayer_area: 64current_crop_outlayer_area: 1current_crop_outlayer_area: 55current_crop_outlayer_area: 30current_crop_outlayer_area: 46current_crop_outlayer_area: 62current_crop_outlayer_area: 24current_crop_outlayer_area: 3current_crop_outlayer_area: 6current_crop_outlayer_area: 1current_crop_outlayer_area: 25current_crop_outlayer_area: 20current_crop_outlayer_area: 47current_crop_outlayer_area: 38current_crop_outlayer_area: 24current_crop_outlayer_area: 3current_crop_outlayer_area: 25current_crop_outlayer_area: 0current_crop_outlayer_area: 28current_crop_outlayer_area: 0current_crop_outlayer_area: 20current_crop_outlayer_area: 48current_crop_outlayer_area: 4current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 48current_crop_outlayer_area: 24current_crop_outlayer_area: 51current_crop_outlayer_area: 14current_crop_outlayer_area: 11current_crop_outlayer_area: 23current_crop_outlayer_area: 29current_crop_outlayer_area: 21current_crop_outlayer_area: 13current_crop_outlayer_area: 31current_crop_outlayer_area: 11current_crop_outlayer_area: 0current_crop_outlayer_area: 26current_crop_outlayer_area: 16current_crop_outlayer_area: 5current_crop_outlayer_area: 20current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 5current_crop_outlayer_area: 3current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 5current_crop_outlayer_area: 3current_crop_outlayer_area: 3current_crop_outlayer_area: 2current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 0current_crop_outlayer_area: 1current_crop_outlayer_area: 3current_crop_outlayer_area: 0current_crop_outlayer_area: 2current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0current_crop_outlayer_area: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/2314792975.py:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  voi = VOI(seg_final.astype(np.int),hand_seg.astype(np.int))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 331, 160) --> (90, 165, 80)\n",
      "progress: 99.71988795518207%\r\rrogress: 42.57703081232493%progress: 43.417366946778714%progress: 44.25770308123249%progress: 44.81792717086835%progress: 45.65826330532213%progress: 47.05882352941176%progress: 47.89915966386555%progress: 48.4593837535014%progress: 49.299719887955185%progress: 49.85994397759104%progress: 50.700280112044815%progress: 51.26050420168067%progress: 52.10084033613446%progress: 53.50140056022409%progress: 54.34173669467787%progress: 55.182072829131656%progress: 56.022408963585434%progress: 57.422969187675065%progress: 57.98319327731093%progress: 58.82352941176471%progress: 60.22408963585434%progress: 61.62464985994398%progress: 62.46498599439776%progress: 63.305322128851536%progress: 63.86554621848739%progress: 64.9859943977591%progress: 66.1064425770308%progress: 66.94677871148458%progress: 67.78711484593838%progress: 68.90756302521008%progress: 69.74789915966386%progress: 70.58823529411765%progress: 71.70868347338936%progress: 72.54901960784314%progress: 73.38935574229691%progress: 74.50980392156863%progress: 75.63025210084034%progress: 76.75070028011206%progress: 78.15126050420169%progress: 79.55182072829132%progress: 80.3921568627451%progress: 81.5126050420168%progress: 82.6330532212885%progress: 83.75350140056022%progress: 84.87394957983193%progress: 86.27450980392157%progress: 87.11484593837535%progress: 88.23529411764706%progress: 89.35574229691878%progress: 90.75630252100841%progress: 91.59663865546219%progress: 92.71708683473389%progress: 93.55742296918767%progress: 95.51820728291317%progress: 97.19887955182072%progress: 98.31932773109243%progress: 99.15966386554622%cell count accuracy iou >0.7: 0.3389355742296919\n",
      "cell count accuracy dice >0.7: 0.4677871148459384\n",
      "cell count accuracy iou >0.5: 0.5014005602240896\n",
      "cell count accuracy dice >0.5: 0.6694677871148459\n",
      "avg iou: 0.47539210659503955\n",
      "avg dice: 0.5889661888981953\n",
      "ari: 0.9913964471796839\n",
      "voi: (1.0957306587105087, 1.3184176191628276)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/32324825.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# mass process\n",
    "seg_final_dict={}\n",
    "accuracy_record_dict = {}\n",
    "ari_dict = {}\n",
    "voi_dict = {}\n",
    "for test_file in HMS_data_dict_test.keys():\n",
    "    print(test_file)\n",
    "    raw_img=np.load(HMS_data_dict_test[test_file][\"raw\"])\n",
    "    hand_seg=np.load(HMS_data_dict_test[test_file][\"ins\"])\n",
    "    accuracy_record, hand_seg_after_accuracy, seg_final_after_accuracy, ari, voi, seg_final=\\\n",
    "    pipeline(raw_img, hand_seg, model, device,\n",
    "             crop_cube_size=64,\n",
    "             stride=32,\n",
    "             test_file_name=test_file)\n",
    "    \n",
    "    seg_final_dict[test_file] = seg_final\n",
    "    accuracy_record_dict[test_file] = accuracy_record\n",
    "    ari_dict[test_file] = ari\n",
    "    voi_dict[test_file] = voi\n",
    "    \n",
    "    iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
    "    print('cell count accuracy iou >0.7: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "    dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
    "    print('cell count accuracy dice >0.7: '+str(sum(dice)/len(dice)))\n",
    "    \n",
    "    iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
    "    print('cell count accuracy iou >0.5: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "    dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n",
    "    print('cell count accuracy dice >0.5: '+str(sum(dice)/len(dice)))\n",
    "\n",
    "    print('avg iou: '+str(np.mean(accuracy_record[:,1])))\n",
    "    print('avg dice: '+str(np.mean(accuracy_record[:,2])))\n",
    "    print(\"ari: \"+str(ari))\n",
    "    print(\"voi: \"+str(voi))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "cell count accuracy iou >0.7: 0.3776595744680851\n",
      "cell count accuracy dice >0.7: 0.5558510638297872\n",
      "cell count accuracy iou >0.5: 0.598404255319149\n",
      "cell count accuracy dice >0.5: 0.75\n",
      "avg iou: 0.5204518265388114\n",
      "avg dice: 0.6381698403943409\n",
      "ari: 0.9887813120768859\n",
      "voi: (1.2387309735901193, 1.1821521195960722)\n",
      "----------\n",
      "120\n",
      "cell count accuracy iou >0.7: 0.4410112359550562\n",
      "cell count accuracy dice >0.7: 0.6207865168539326\n",
      "cell count accuracy iou >0.5: 0.651685393258427\n",
      "cell count accuracy dice >0.5: 0.8061797752808989\n",
      "avg iou: 0.5608052647197777\n",
      "avg dice: 0.6762947715829346\n",
      "ari: 0.9903133216110687\n",
      "voi: (1.1912324053886543, 1.1117598943602993)\n",
      "----------\n",
      "65\n",
      "cell count accuracy iou >0.7: 0.27960526315789475\n",
      "cell count accuracy dice >0.7: 0.42105263157894735\n",
      "cell count accuracy iou >0.5: 0.46710526315789475\n",
      "cell count accuracy dice >0.5: 0.6710526315789473\n",
      "avg iou: 0.4862710802262882\n",
      "avg dice: 0.6148497683860018\n",
      "ari: 0.9909201284033261\n",
      "voi: (1.2584500794969642, 1.3278350462874742)\n",
      "----------\n",
      "90\n",
      "cell count accuracy iou >0.7: 0.3389355742296919\n",
      "cell count accuracy dice >0.7: 0.4677871148459384\n",
      "cell count accuracy iou >0.5: 0.5014005602240896\n",
      "cell count accuracy dice >0.5: 0.6694677871148459\n",
      "avg iou: 0.47539210659503955\n",
      "avg dice: 0.5889661888981953\n",
      "ari: 0.9913964471796839\n",
      "voi: (1.0957306587105087, 1.3184176191628276)\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/583679840.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/583679840.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/583679840.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
      "/var/folders/qq/9q6wphrj19z8xt4qcffm8df80000gn/T/ipykernel_23973/583679840.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "for item in seg_final_dict.keys():\n",
    "    print(item)\n",
    "    accuracy_record = accuracy_record_dict[item]\n",
    "    ari = ari_dict[item]\n",
    "    voi = voi_dict[item]\n",
    "    iou=np.array(accuracy_record[:,1]>0.7, dtype=np.float)\n",
    "    print('cell count accuracy iou >0.7: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "    dice=np.array(accuracy_record[:,2]>0.7, dtype=np.float)\n",
    "    print('cell count accuracy dice >0.7: '+str(sum(dice)/len(dice)))\n",
    "    \n",
    "    iou=np.array(accuracy_record[:,1]>0.5, dtype=np.float)\n",
    "    print('cell count accuracy iou >0.5: '+str(sum(iou)/len(iou)))\n",
    "\n",
    "    dice=np.array(accuracy_record[:,2]>0.5, dtype=np.float)\n",
    "    print('cell count accuracy dice >0.5: '+str(sum(dice)/len(dice)))\n",
    "\n",
    "    print('avg iou: '+str(np.mean(accuracy_record[:,1])))\n",
    "    print('avg dice: '+str(np.mean(accuracy_record[:,2])))\n",
    "    print(\"ari: \"+str(ari))\n",
    "    print(\"voi: \"+str(voi))\n",
    "    print(\"----------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_foreground_comp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m how_close_are_the_super_vox_to_boundary\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      4\u001B[0m min_touching_percentage\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.51\u001B[39m\n\u001B[0;32m----> 6\u001B[0m seg_foreground_erosion\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mimg_3d_erosion_or_expansion(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[43mseg_foreground_comp\u001B[49m, kernel_size\u001B[38;5;241m=\u001B[39mhow_close_are_the_super_vox_to_boundary\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m      7\u001B[0m seg_foreground_super_voxel_by_ws \u001B[38;5;241m=\u001B[39m generate_super_vox_by_watershed(seg_foreground_erosion, connectivity\u001B[38;5;241m=\u001B[39mmin_touching_area)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'seg_foreground_comp' is not defined"
     ]
    }
   ],
   "source": [
    "# see the difference for supervoxels\n",
    "\n",
    "how_close_are_the_super_vox_to_boundary=2\n",
    "min_touching_percentage=0.51\n",
    "\n",
    "seg_foreground_erosion=1-img_3d_erosion_or_expansion(1-seg_foreground_comp, kernel_size=how_close_are_the_super_vox_to_boundary+1, device=device)\n",
    "seg_foreground_super_voxel_by_ws = generate_super_vox_by_watershed(seg_foreground_erosion, connectivity=min_touching_area)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N=100\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "plt.title(\"supervoxels\")\n",
    "plt.axis('off')\n",
    "plt.imshow(seg_foreground_super_voxel_by_ws[:,:,N])#, cmap=\"gray\")\n",
    "#plt.savefig('_RGB_'+str(N)+'.png',bbox_inches='tight',dpi=fig.dpi,pad_inches=0.0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}